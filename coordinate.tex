\documentclass[12pt,letter]{article}
\usepackage[DIV=14,BCOR=2mm,headinclude=true,footinclude=false]{typearea}
\renewcommand{\baselinestretch}{1.15} 
\usepackage{latexsym}
\usepackage{amsmath}

%\usepackage{MinionPro}
\usepackage{amssymb}

\usepackage{hyperref}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{natbib}
\usepackage{color, colortbl}
\usepackage{appendix}
\usepackage{amsmath,amsthm}


\usepackage{wasysym}


\usetikzlibrary{arrows,shapes}

\definecolor{Gray}{gray}{0.9}

\newtheorem{result}{Result}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{assumption}{Assumption}[section]


\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\theoremstyle{claim}
\newtheorem{claim}{Claim}


\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\tikzstyle{vertex}=[circle,fill=black!25,minimum size=12pt,inner sep=0pt]
\tikzstyle{selected vertex} = [vertex, fill=red!24]
\tikzstyle{edge} = [draw,thick,-]
\tikzstyle{weight} = [font=\small]
\tikzstyle{selected edge} = [draw,line width=5pt,-,red!50]
\tikzstyle{ignored edge} = [draw,line width=5pt,-,black!20]


%\linespread{1.5}

\begin{document}
%\fontsize{12}{20pt}\selectfont

\title {Coordination in Social Networks: Communication by Actions}
\author {Chun-Ting Chen}
\date{This Version: November, 2014}
\maketitle

\begin{abstract}

This paper studies a collective action problem in a setting of discounted repeated coordination games in which players know their neighbors'  inclination to participate as well as monitor their neighbors' past actions. I define \textit{strong connectedness} to characterize those states in which, for every two players who incline to participate, there is a path consisting of players with the same inclination to connect them.  Given that the networks are fixed, finite, connected, commonly known, undirected and without cycles, I show that if the priors have full support on the strong connectedness states, there is a (weak) sequential equilibrium in which the ex-post efficient outcome repeats after a finite time $T$ in the path when discount factor is sufficiently high. This equilibrium is constructive and does not depend on public or private signals other than players' actions.




\end{abstract}


\section{Introduction} 

This paper studies collective actions in a setting of discounted repeated coordination games, where information and monitoring structures are modeled as networks. Players are uncertain about the states of nature but can observe their neighbors' actions. I would like to explore what kinds of networks can induce players to solve the underlying uncertainty in order to coordinate with the ex-post efficient outcome. Though the motive of this study is to understand the dynamic of social movements, a general interest centers on the collective action behaviors within social structures.

Consider pro-democracy movements. Strong discontents overthrowing a regime may exist, but it is difficult to organized around these discontents because information about the existence of such discontents is not always transparent. For instance, in East Germany, the government had control over the electoral system and the mass media, and the eavesdropping by secret agents had impeded people from showing their discontents. As \citep{Karl-Dieter1993} or \citep{Chwe2000} have suggested, such discontents may be revealed only to someone whom you trust or have an intimate relationship with, but are hardly revealed publicly. This lack of common knowledge about the existence of strong discontent may impede people from conducting a one-shot uprising due to the fear of possible failure (e.g., \citep{Chwe2000} in proposing a static model to characterize the networks that provide common knowledge about peoples' discontents). However, an event may trigger a later event (e.g., \citep{Lohmann2011} in using informational cascade model to explain consecutive demonstrations in East Germany 1989-1991). When rebels are aware of the scale to transmit relevant information about the level of collective discontent through their actions, they might be willing to act although it might be at risk of facing failure. I view such risky actions as a part of an equilibrium strategy and the entire movement as a learning process. 




Inspired by \citep{Chwe2000}, I model such dynamic collective action in the following way. Players repeatedly play a $k$-\textit{Threshold game} with a parameter $k$ in a network. There are two types of players located in the network, one we called them \textit{Rebel} and one we called them \textit{Inert}.  Players' types and their actions can be observed only by their neighbors. A Rebel has two actions, which are \textbf{revolt} or \textbf{stay}, while an Inert has only one action, which is \textbf{stay}. A Rebel will get payoff as $1$ if he chooses \textbf{revolt} and more than $k$ players choose \textbf{revolt}; he will get payoff as $-1$ if he chooses \textbf{revolt} and less than $k$ players choose \textbf{revolt}; he will get payoff as $0$ if he chooses \textbf{stay}. An Inert will get payoff as $1$ if he chooses \textbf{stay}.

Since a Rebel may not know how many Rebels exist in this world, Rebels' payoff structure captures the idea that \textbf{stay} is a safe arm and \textbf{revolt} is a risky arm. Given a common prior $\pi$ over players' types, players play this $k$-Threshold game infinitely repeatedly with a common discount factor $\delta$. Cheap talk is not allowed, no outside mechanism serves as an information exchange device. 

Rebels then communicate with each other by playing actions. For different $k$ and different network structures, I am looking for a sequential equilibrium which has the property of \textit{approaching ex-post efficient} (\textit{APEX} henceforth) to investigate the information sharing behavior in the networks. An equilibrium is APEX if and only if {the tails of actions in the equilibrium path repeats the static ex-post efficient outcome after a finite time $T$}.  This refinement serves to check if players have already learned the relevant information in the equilibrium path. If there are at least $k$ Rebels in this society, then \textit{all} Rebels should \textbf{revolt} after $T$ as if they have known that more than $k$ Rebels exist; otherwise, \textit{all} Rebels should \textbf{stay} after $T$. The Rebels' incentives to communicate are affected by their positions in networks since networks are structuring the information and monitoring structure.

In order to get a quick intuition about Rebel's learning process in the proposed framework, consider the $k$-Threshold game with $k=n$ and assume that payoff is hidden. When $k=n$, a Rebel can get positive payoff only if all the players are Rebels. Given that the networks are fixed, finite, connected, commonly known, and undirected (\textit{networks} henceforth), an APEX sequential equilibrium can be constructed by a contagion-like argument. This argument is to treat \textbf{stay} as the message of ``there is an Inert out there''; and treat \textbf{revolt} as the message of ``there could be no Inert out there ''. If a Rebel has an Inert neighbor, then he plays \textbf{stay} forever. If he has no Inert neighbors, then he plays \textbf{revolt} until he observes that some of his neighbors play \textbf{stay}, and then he shifts to play \textbf{stay} forever. Since the networks are finite,  within finite periods, a Rebel will learn that there is an Inert out there if some neighbors have played \textbf{stay} and learn that there is no an Inert out there otherwise.

The non-trivial cases appear when $k<n$. The $k=n$ case is easier because the underlying relevant information is to tell ``Is there an Inert out there?''. I can construct equilibrium when $k=n$ by using single-period binary actions, $\{\textbf{stay},\textbf{revolt}\}$, to separate the states into two parts, ``no Inerts'' or ``some Inerts''. In other words, these single-period actions can generate distinguishable distribution of signals to inform players in telling the true states of nature\footnote{e.g., \citep{Fudenberg2010} or \citep{Fudenberg2011}.}. However, when $k<n$, the relevant information is to tell ``Are there at least $k$ Rebels out there?'', and thus these binary actions have to carry more information to reveal the states. As I will show later, several sequences of actions will be used to transmit Rebels' private informations and to control Rebels' beliefs in equilibrium. In the equilibrium path, two kinds of sequence will be used. The first kind, \textit{reporting messages}, is to report their private information about the states of nature; the second one, \textit{coordination messages}, is to inform Rebels about whether some other Rebels have known the relevant information.  Specifically, in the equilibrium path, Rebels will play the coordination message to inform other Rebels whenever they have known the relevant information, and those other Rebels will play the same message again to inform other Rebels. The coordination message means to serve as a short-cut to track individuals' higher-order beliefs about ``Have some Rebels known the relevant information?'', ``Have some Rebels known some Rebels have known the relevant information?'', etc.


Note that communication is costly in the sense that playing \textbf{revolt} is risky. Due to being discounting, Rebels always seek the opportunity to manipulate their messages to save their costs in the time horizontal line\footnote{Indeed, allowing cheap talk or using limit-of-mean preference (e.g., \citep{Renault1998}) will solve this coordination problem.}. A free rider problem may occur when reporting information incurs costs. I give an example here to illustrate this issue. Consider a situation where two nearby Rebels exchange information \footnote{Example~\ref{ex_free_rider_tree}}. Suppose that these two Rebels can learn the true state after acquiring information from each other's truthful reporting. Furthermore, we suppose that each of them can freely initiate the coordination after exchanging information. In this instance, truthful reporting is not the best response because a player can wait given that the other will report truthfully. The intuition behind the above scenario is to see the future coordination as a public good. This public good can only be made by Rebels' truthful reporting, which incurs some costs.


The main result will show that this coordination problem can be solved in the {acyclic} networks . Here, I define a \textit{path} in $G$ is a sequence consisting of nodes without repetition in which a node is a neighbor of a previous node. Then I define an undirected network acyclic $G$ by defining a network in which the path between different nodes is unique. After I define \textit{strong connectedness} as the property that there is always a path consisting of Rebels to connect any pairs of Rebels,  the main result shows:

\begin{result}\textbf{(Main Result)}
For $n$-person repeated $k$-Threshold game with parameter $1\leq k \leq n$ played in any acyclic network, if $\pi$ has full support on the strong connectedness, then , there is a $\delta^{*}$ such that a (weak) APEX sequential equilibrium exists whenever $\delta>\delta^{*}$.  
\end{result}

Here, the assumption that $\pi$ has full support on strong connectedness means that $\pi$ assigns positive probability on same states if and only if those states exhibit strong connectedness. This assumption is to make sure that the underlying game is not reduced to an incomplete information game which is without communication.  To see this, recall that an Inert always plays \textbf{stay}. Rebels cannot communicate with some Rebels by their actions if an Inert happens to separate them. For instance, in a wheel network, an incomplete game without communication is that the central player is an Inert while the peripheral players are all Rebels. It is impossible to find an APEX equilibrium in this instance unless $k=1$.

The off-path belief serves as a grim trigger as follows. Whenever a Rebel detects a deviation, he believes that all other players outside his neighborhood are Inerts. Thus, if there are less than $k$ Rebels in his neighborhood, he will play \textbf{stay} forever. With this off-path belief and the constructed equilibrium strategies, the belief system satisfies \textit{updating consistency}(\citep{Perea2002}), while it may not satisfy full consistency (\citep{Krep_Wilson1982}). \footnote{ Updating consistency requires that, for every player, for every player's strategies, for every information sets $s^1,s^2$ where $s^2$ follows $s^1$, if $s^2$ happens with positive probability given $s^1$ and given players' strategies contingent on $s^1$, then the belief over $s^2$ should satisfy Bayesian updating conditional on the belief over $s^1$ and players' strategies contingent on $s^1$. In other words, the updating consistency require that players hold beliefs in every information sets and hold updated beliefs that follows previous beliefs. This requirement imposes restrictions on off-path beliefs that induce sequential rationality, although it is weaker than full consistency in the sense that full consistency implies updating consistency.}

The establishment of an equilibrium construction starts from building a communication protocol. By exploiting the assumption of finite and commonly known network, I assign each node a distinct prime number. Then I let reporting messages carry the information about the multiplication of nodes' prime numbers. Since the multiplication of prime numbers can be defactorized uniquely, the reporting messages thus carry the information about those nodes' locations in a network. Next, I let two phases, reporting period and coordination period, occur in turns in the time horizon, where the reporting (resp. coordination) messages are played in the reporting (resp. coordination) period. In the coordination period, whenever a Rebel tells the relevant information, such Rebel inform his nearby Rebels by sending coordination messages. Those nearby Rebels then continue to inform their nearby Rebels by sending coordination messages, etc. Then, after the coordination period, if a Rebel has received a coordination message, he is certain that all Rebels have commonly known that they can tell the relevant information. 

I call a complete two-phases, starting from a reporting period and ending with a following coordination period, a \textit{block}.  In a block, I control the inter-temporal incentives in playing between reporting and coordination messages as follows. First, I let both of the coordination messages, one of them can initiate the coordination to \textbf{revolt} and another one can initiate the coordination to \textbf{stay}, incur no expected cost. Second, I let Rebels play \textbf{revolt} after a block only if they have observed the coordination message to \textbf{revolt} and observed some reporting messages  which incur some expected costs. However, the continuation behavior after observing the coordination message to \textbf{stay} is not contingent on any reporting message. When a Rebel looks forward future coordination to \textbf{revolt}, he may have the incentive to take a risk to influence Rebels' future behavior forwardly; otherwise, he just plays \textbf{stay}. Next, in the equilibrium path, I make sure that Rebels will play ex-post efficient outcome repeatedly right after a block if some Rebels have initiated the coordination in that block. I will argue that only those Rebels who have been able to tell the relevant information after reporting period have the incentive to initiate the coordination. This is because they do not need further evidence to prove that whether the revolution will be successful. This argument is to show that a Rebel other than them will not take advantage to send that free coordination message to initiate the coordination. This is because players cannot update further information if all of their neighbors continue to play the same actions in the future. When $\delta$ is high enough, he will not initiate the coordination to impede his own learning process to achieve the ex-post efficient outcome.

I then characterize Rebels' incentive in taking risks and control how much \textbf{revolt} they should play to sustain an APEX equilibrium. In the equilibrium path, a Rebel iteratively updates his relevant information given other Rebels' \textbf{revolt}-\textbf{stay} finite sequence in reporting their information about the state, and a Rebel takes risks only if his current relevant information has not been acquired by other Rebels. In the equilibrium path, a Rebel thus believes that ``more other Rebels are out there'' if and only if his nearby Rebels take risks to report their existence. Some specified forms of reporting messages are introduced, and the off-path belief is to enforce Rebels not to play differently from them.

The key step here is to construct a special reporting message which incurs the least expected cost in taking risks, and this message should be considered as a part of the equilibrium path. I denote this special reporting message as $\langle 1 \rangle$. To see its importance, consider the concept of pivotal Rebel. Here, a pivotal Rebel is defined as the Rebel who is sure that he can know the relevant information right after a reporting period given that other Rebels will report their information truthfully. Now suppose playing $\langle 1 \rangle$ is not considered as a part of the equilibrium path, and suppose a Rebel finds himself as a pivotal Rebel during a reporting period while he has not yet reported anything in that period. It could be possible for him to find a profitable deviation by taking less risks (i.e. by playing less \textbf{revolt}), which can not be detected by at least $k$ Rebels although some Rebels can indeed detect such deviation. Since those Rebels who detected such deviation will play \textbf{stay} forever by the off-path belief, and this pivotal Rebel can initiate the coordination to \textbf{revolt} by convincing other Rebels to play \textbf{revolt}, the APEX fails. To solve this problem, I introduce message $\langle 1 \rangle$ to let pivotal Rebels identify themselves, while I let coordination messages to \textbf{revolt} or to \textbf{stay} have to be initiated when $\langle 1 \rangle$ has been played in the equilibrium path to prevent non-pivotal Rebels from mimicking pivotal Rebels.

The major difficulties remaining to solved are the situations where there are multiple pivotal players nearby each other. In such phenomenon, the APEX may fail since playing $\langle 1 \rangle$ does not answer ``how many Rebels has a pivotal Rebel known?'' although it does address ``a pivotal Rebel exists''. The assumption of acyclic networks is crucial of solving these problems. If the networks are acyclic, I will show it later that there are only two kinds of pivotal Rebels. One kind is that they have known there are at least $k-1$ Rebels. The other kind is that they will know the true state given other Rebel neighbors' truthful reporting. I call the latter case a free rider problem. If the networks are acyclic, Lemma ~\ref{lemma_at_most_two_nodes} will show that the free rider problems only happen between two nearby pivotal Rebels in only one block in the equilibrium path. Further, these two nearby Rebels will know that this free rider problem will occur before the game entering into this block. The consequence of Lemma ~\ref{lemma_at_most_two_nodes} is that, before the game entering into this block, I can let arbitrary one of them report the information about the state and let the other one play $\langle 1 \rangle$ dependent on their indexed prime numbers.
\footnote{
Such scenario substantially differs from the cyclic counterpart. The free rider problem becomes intractable in cyclic networks. Let's consider the following example, in which there are 5 players in a cyclic network. Player $i$ is a Rebel and labeled as \textit{RB} if $i\in\{1,2,3,4,\}$; is an Inert if $i\in\{5\}$.

\begin{center}
\begin{tikzpicture}[scale=1]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(2,3)/RB_1}, {(3,2)/RB_2}, {(5,2)/RB_3}, {(6,3)/RB_4}, {(4,5)/5}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in { RB_1/RB_2, RB_2/RB_3, RB_3/RB_4, RB_4/5, 5/RB_1}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

Let's suppose $k=4$ and assume that, at a certain period $t$, players know only their immediate neighbors' types. Let's further simplify the scenario and suppose that any Rebel player can exchange information with his neighbors by talking that incurs a fixed cost $c$ at period $t+1$, as well as freely initiate coordination at $t+2$. In such a scenario, for \textit{any} set of players, the answer to ``Who are the pivotal players before entering $t+1$?'' is not certain at $t$. Take the set of players $\{1,2\}$ as an example, and notice that, from the perspective of player 2, the type of player 5 could be Inert. Therefore, player 2 does not know whether player 1 is a pivotal player though player 2 himself is one. (In this case, player 1 is indeed not a pivotal player.) Similarly, player 2 does not know whether player 3 is a pivotal player even player 3 is indeed a pivotal player. The arbitrary selection of free riders, say by choosing player 1, might then fail to reach coordination at $t+2$. 

However, if we can cut the edge between player 4 and player 5 such that the network becomes a tree, player 2 knows that he is the only pivotal player.
}





This paper contributes to several fields of economics. 

First, the future coordination can be viewed as a public good among all Rebels. A strand of public good literature, such as \citep{Lohmann1994}, is to view information as a public good while generating information is costly\footnote{For instance, \citep{Lohmann1993}\citep{Lohmann1994} consider that individuals generate information by their actions, where the aggregate outcomes of actions is public. \citep{Bolto_Harris1999} consider team experiment in infinite time horizon where the outcomes of experiments are public signals. \citep{Bramoulle2007} view information as a public good and consider public good provision in networks.}. This paper models costly information generation, while adding another aspect, network-monitoring, to investigate a collective action behavior.

Second, this paper is also related to the literature of social learning\footnote{Reviews can be seen in \citep{Bikhchandani1998} \citep{Cao2001}.}. Several papers have considered social learning in networks \footnote{\citep{Goyal2012} gives the reviews. Recent papers, e.g., \citep{Acemoglu2011}\citep{Chatterjee2011}, also discuss this topic}. In this literature, when players are myopic, the information flows could be very complicated because the information they sent can in turns affect their future behaviors. For instance, in \citep{RePEc:eee:gamebe:v:45:y:2003:i:2:p:329-346},  even for 3-person connected undirected networks, the complete network and incomplete network will give different convergence results which highly depend on individuals' initial private signals and their allocations in a network. In \citep{Golub2010}, instead of using Bayesian learning, they use a naive learning protocol to tackle this social learning problem. I consider the social learning in networks as a learning-in-game procedure, where individuals can put more weights on the future learning results. My result gives a hint that the shape of network (without cycle) did not matter too much if players are far-sighted.

Third, a growing literature considers the game played in networks where various games played in various networks with various definitions\footnote{\citep{Jackson2008}\citep{Goyal2012} gives the reviews.}. Only avfew papers in this literature discuss the repeated game. In complete information game. In \citep{Laclau2012}, she proves a folk theorem where players play the game locally. In \citep{Wolitzky2013} \citep{Wolitzky2014}, he considers network-like monitoring where a prisoner dilemma game is played globally. My paper is the first paper to consider the incomplete information game repeatedly played in a network. 

My paper is also related to the literature in folk theorems in discounted repeated games with incomplete information. In this literature, they consider more general games than the games adopted here. \citep{Fudenberg2010} \citep{Fudenberg2011} \citep{Wiseman2012} considering $n$-person game with public signals jointly generated by the states and actions; \citep{Yamamoto2014} considering $2$-person game with private signals jointly generated by the states and actions. There, the full-rank conditions are imposed to let single-period actions generate informative signals to separate the states. Here, I consider $n$-person game without signals and thus the single-period full-rank conditions are not imposed before solving the equilibrium.  And my result shows that acyclic networks are sufficient to sustain the ex-post efficiency when discount factor is sufficiently high. 



The paper is organized as the followings. I introduce the model in Section ~\ref{sec:model} . I discusses the equilibrium construction and shows the main result in Section ~\ref{sec:equilibrium_1} and Section ~\ref{sec:equilibrium_2} respectively. Some variations of my model will be discussed in its subsection ~\ref{sec:varies}. The conclusion is made within Section ~\ref{sec:con}. All the missing proofs can be found in Appendix~\ref{appx_network}.

\section{Preliminaries}
\label{sec:model}
\subsection{Notations}
Given a finite set $A$, denote $\#A$ as the cardinality of a set $A$, and denote $\Delta A$ as the set of probability distribution over $A$. 

The square bracket $[]$ that follows a quantifier $\exists, \forall$ will be read as ``\textit{such that}''. For instance, $\exists a \in A [c\in A, c=a]$ will be read as ``exists $a$ in $A$ such that $c$ in A and $c$ is equal to $a$.'' .
\subsection{Model}


There are $n$ players. Denote $N=\{1,2,...,n\}$ as the set of players.  

We say $G$ is a graph if $G$ is a point-to-set function mapping from $N$ to a subset of $N$ containing $i\in N$. Moreover, we denote $G_i=G(i)$ as $i$'s neighbors and also denote $\bar{G}_i=G_i\backslash \{i\}$ as $i$'s neighborhood excluding $i$ self. We say that $G$ is fixed if and only if $G$ is not random. We say that $G$ is undirected if and only if for all $i,j$ if $j\in G_i$ then $i\in G_j$. A path from $i$ to $j$, $i\neq j$ in an undirected network $G$ is a finite sequence $l_1,...,l_q$ such that $l_1=i, l_2\in \bar{G}_{l_1}, l_3\in \bar{G}_{l_2},...,l_q=j$ and there is no repetition in $\{l_1,...,l_q\}$. An undirected network is connected if and only if for all $i,j$, $i\neq j$ there is a path from $i$ to $j$. Throughout this paper, I call $G$ a network if the graph $G$ is finite, fixed, commonly known, connected, and undirected. 

For all player $i$, let $\Theta_i=\{Rebel,Inert\}$ be the set of $i$'s type and denote $\theta_i\in \Theta_i$ as $i$'s type. The set of states of nature is $\Theta=\prod_{j\in N}\Theta_j$ and let $\theta\in \Theta$ be a state of nature. Let $\Theta_{G_i}=\prod_{j\in G_i}\Theta_j$ be the set of $i$'s neighbors' types and let $\theta_{G_i}\in \Theta_{G_i}$ be an element in it. Let $p_{G_i}:\Theta \rightarrow 2^{\Theta}$ be $i$'s information partition function such that $p_{G_i}(\theta)=\{\theta_{G_i}\}\times \prod_{j\not\in G_i}\Theta_j$.  Denote $\mathcal{P}_{G_i}=\{p_{G_i}(\theta)\}_{\theta\in \Theta}$ as $i$'s information sets about $\theta$. For convenience, I also denote $[Rebels](\theta)=\{j:\theta_j=Rebel\}$ be the set of Rebels given $\theta$.

There is a game, $k$-threshold game, infinitely repeated played with common discounted factor $\delta$ in a fixed $G$. Time is discrete, infinite horizontal. At the beginning of this game, a state is realized and there is a common prior $\pi\in \Delta \Theta$ over $\Theta$. After a state is realized, players simultaneously choose an action $a_{\theta_i}\in A_{\theta_i}$ in each period afterwards. If $\theta_i=Rebel$, then $A_{\theta_i}=\{\textbf{revolt}, \textbf{stay}\}$.  If $\theta_i=Inert$, then $A_{\theta_i}=\{\textbf{stay}\}$. Let $a_{\theta_i}\in A_{\theta_i}$ be $i$'s action if $i$'s type is $\theta_i$, and let $a_{-\theta_i}\in \Pi_{j\in N,j\neq i}A_{\theta_j}$ be the actions taken by players other than $i$. Player $i$'s static payoff function is denoted as $u_{\theta_i}: \Pi_{j\in N}A_{\theta_j}\rightarrow \mathbb{R}$. In this $k$-threshold game, $i$'s static payoff is defined as followings. 
\begin{enumerate}
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=1$ if $a_{Rebel_i}=\textbf{revolt}$ and $\#\{j:a_{\theta_j}=\textbf{revolt}\}\geq k$
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=-1$ if $a_{Rebel_i}=\textbf{revolt}$ and $\#\{j:a_{\theta_j}=\textbf{revolt}\}< k$
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=0$ if $a_{Rebel_i}=\textbf{stay}$
\item $u_{Inert_i}(a_{Inert_i},a_{-\theta_i})=1$ if $a_{Inert_i}=\textbf{stay}$
\end{enumerate}

Players can only observe their neighbors' actions. In order to emphasize that their payoffs are not the signals for them to infer others' actions, I assume that payoffs are hidden until Section \ref{sec:varies}. To be more precise, let $s\geq 0$ be a period. Let $H^0_{i}=\{ \emptyset \}$ and let $H^s_{i}=H^0_{i}\times \prod^s_{t=1}A_{\theta_i}$ be the set of histories of actions played by player $i$ up to period $s$. Let $H^0_{G_i}=\{\emptyset\}$ and let $H^s_{G_i}=H^0_{G_i}\times \prod^s_{t=1}\prod_{j\in G_i}A_{\theta_j}$ be the set of histories player $i$ can observe up to period $s$.  For convenience, also denote $H^0=\{\emptyset\}$, $H^s=H^0\times \prod^s_{t=1}\prod_{j\in N}A_{\theta_j}$, and $H=H^0\times \prod^{\infty}_{s=1}\prod_{j\in N}A_{\theta_j}$ with generic element $h\in H$. Up to period $s$, $i$'s information sets about histories of actions is $\mathcal{H}^s_{G_i}=\{\{h^s_{G_i}\}\times \prod_{j\notin G_i}H^s_{j}\}_{h^s\in H^s}$, where $h^s_{G_i}\in H^s_{G_i}$.

$i$'s pure strategy is a function $\tau_{\theta_i}:(\prod_{j\in G_i}\Theta_j)\times \bigcup^{\infty}_{s=0}H^s_{G_i}\rightarrow A_{\theta_i}$. For convenience, also let $\tau=\{\tau_{\theta_i}\}_i$. 
 
The prior $\pi$, the network $G$, and $\tau$ induce a joint distribution, denoted as $\gamma^{\pi,\tau}_G$, over $\Theta\times H$. Given a realization $(\theta,h)$ according to $\gamma^{\pi,\tau}_G$, let $h^{\tau}_\theta$ be the realized sequence of actions generated by $\tau$ given $\theta$. 

Denote $\alpha^{\pi,\tau}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i})$ as the conditional distribution over $\Theta\times H^s$ conditional on $\theta_{G_i}\in \Theta_{G_i}$ and $h^{s}_{G_i}\in H^s_{G_i}$ induced by $\tau$ for player $i$ at period $s$. For convenience, also denote $\beta^{\pi,\tau}_{G_i}(\theta|\theta_{G_i},h^{s}_{G_i})=\sum_{h^{s}\in H^s}\alpha^{\pi,\tau}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i})$.
Finally, let
$E^{\delta}_G(u_{\theta_i}(\tau)|\alpha^{\pi,\tau}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i}))$
be $i$'s continuation expected payoff conditional on $\theta_{G_i}$ and $h^{s}_{G_i}$ induced by $\tau$. 



Let $\mathcal{A}^s_{G_i}=\mathcal{P}_{G_i}\times \mathcal{H}^s_{G_i}$ be $i$'s information sets at period $s$, and let $\mathcal{A}_{G_i}=\prod^{\infty}_{s=0}\mathcal{A}^s_{G_i}$ be $i$'s information sets. The equilibrium concept here is the week sequential equilibrium. A weak sequential equilibrium is a pair of $\{\tau^{*}, \alpha^{*}\}$, where $\alpha^{*}$ is a collection of distributions over players' information sets with the property that, for all $i$, for all $s$, $\alpha^{*}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i})=\alpha^{\pi,\tau^{*}}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i})$ whenever $A^s_{G_i}\in \mathcal{A}^{s}_{G_i}$ is reached with positive probability given $\tau^{*}$. For all $i$, for all $s$, the $\tau^{*}_{\theta_i}$ maximize $i$'s continuation expected payoff conditional on $\theta_{G_i}$ and $h^{s}_{G_i}$
\[E^{\delta}_G(u_{\theta_i}(\tau_{\theta_i},\tau^{*}_{-\theta_i})|\alpha^{\pi,\tau_{\theta_i},\tau^{*}_{-\theta_i}}_{G_i}(\theta, h^{s}|\theta_{G_i},h^{s}_{G_i}))\] for all $h^{s}_{G_i}$. 





I am looking for a weak sequential equilibrium which is APEX. 

\begin{definition}
A strategy $\tau$ is APEX  if and only if, for all $\theta$, there is a finite time $T^{\theta}$ such that the actions in $h^{\tau}_{\theta}$ after $T^{\theta}$ repeats the static ex-post Pareto efficient outcome.
\end{definition}

\begin{definition}\label{Def_expost_efficient}
A weak sequential equilibrium $(\tau^{*},\alpha^{*})$ is APEX if and only $\tau^{*}$ is APEX.
\end{definition}




In other words, in an APEX strategy profile, all the Rebels play \textbf{revolt} forever after some finite periods if there are more than $k$ Rebels; otherwise, Rebels play \textbf{stay} forever after some finite periods. 


 \subsection{An Illustrative Example}


The following example shows that an APEX equilibrium can be founded if $\delta$ is high enough. In this example, a Rebel (Rebel 2) plays the roles as a coordinator to reveal the relevant information to others.
\begin{example}\label{ex_leading_ex}
Suppose there are 3 players in a network.  This network is set as $G_1=\{1,2\}$, $G_2=\{1,2,3\}$,and $G_3=\{2,3\}$ as the following graph.

\begin{center}
\begin{tikzpicture}[scale=1.5]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,0)/1}, {(2,0)/2}, {(3,0)/3}}
        \node[vertex] (\name) at \pos {$\name$};
    % Connect vertices with edges 
    \foreach \source/ \dest in {1/2, 2/3}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

They play the repeated $k$-threshold game with $k=3$. Note that after nature moves, player 2 can observe the true state of nature $\theta$, while player 1 or 3 are not. Player 2 plays the role as a coordinator. We can construct an equilibrium which is APEX as the followings. 

\begin{itemize}
\item After nature moves, Rebel 2 chooses $\textbf{revolt}$ if he observes $\theta=(Rebel,Rebel,Rebel)$, and plays \textbf{revolt} in this period. Otherwise, he chooses \textbf{stay} and keeps playing \textbf{stay} afterwards. 
\item After nature moves, Rebel 1 and Rebel 3 play \textbf{stay}.
\item If Rebel 2 chooses \textbf{revolt} in the last period, then Rebel 1 (or Rebel 3) plays \textbf{revolt} in this period; if Rebel 2 chooses \textbf{stay} in the last period, then Rebel 1 (or Rebel 3) keeps playing \textbf{stay} afterwards. 
\item If a Rebel deviates from the above strategy, he will play \textbf{stay} forever; if a Rebel detects a deviation,he will play \textbf{stay} forever.
\end{itemize}

It is straightforward to check that the above strategies constitute an equilibrium if $\delta\geq \frac{1}{2}$. In the equilibrium path, Rebel 1 and Rebel 3 believe that $\{\theta:\#[Rebels](\theta)\geq 3\}$ with probability one if they observe that Rebel 2 has played \textbf{revolt} and believe $\{\theta:\#[Rebels](\theta)< 3\}$ with probability one if Rebel 2 has played \textbf{stay}. Outside of the equilibrium path, Rebels arbitrary form their beliefs.
\end{example}



\subsection*{}
I begin to find an APEX equilibrium in general cases.

\section{Equilibrium: $k=n$}
\label{sec:equilibrium_1}


In Example~\ref{ex_leading_ex}, the construction of an APEX equilibrium relies on some important features. First, since $k=n$, Rebel 2 will never play \textbf{revolt} if one of his neighbor is Inert. Thus, when Rebel 2 plays \textbf{revolt}, it must be the case that all Rebel 2's neighbor are Rebels.  Second, Rebel 1 or Rebel 3 can force Rebel 2 to play \textbf{revolt} to reveal the true state in the first period since only Rebel 2 knows the true state and Rebel 2's actions can separate the states. Third, since $k=n$, one Rebel's shifting to play \textbf{stay} forever is enough to punish a deviation, and so that the group punishment is not necessary. For instance, if a Rebel did not play \textbf{revolt} in the first period at the state $\theta=(Rebel,Rebel,Rebel)$, his neighbor can punish him by playing \textbf{stay} forever. This punishment is credible by letting that player who deviates also plays \textbf{stay} forever. 

I state my result for $k=n$ case as follows.

\begin{theorem}
\label{prop:not_crowded}
For any $n$-person repeated $k$-Threshold game with parameter $k=n$ played in a network, then there is a $\delta^{*}$ such that a sequential APEX equilibrium exists whenever $\delta>
\delta^{*}$.
\end{theorem}
\begin{proof}
Let a strategy profile, $\tau^{*}$, as follows. After nature moves, a Rebel plays \textbf{revolt} if he has no Inert neighbor; a Rebel plays \textbf{stay} forever if he has an Inert neighbor. After first period, if a Rebel has not detected a deviation, and if such Rebel observes that his Rebel neighbors play \textbf{revolt} continuously in the last periods, he keeps playing \textbf{revolt} in the current period; otherwise, he plays \textbf{stay} forever. If a Rebel deviates, then he play \textbf{stay} forever.

According to $\tau^{*}$, at period $s$, if a Rebel has not detected a deviation and if such Rebel observes his Rebel neighbors have played \textbf{stay} once in the last periods, he forms belief $\sum_{\theta:\#[Rebels](\theta)\geq k}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})=0$ after period $s$, and therefore playing \textbf{stay} after period $s$ is his best response. If a Rebel detects a deviation or he has deviated to play \textbf{stay}, playing \textbf{stay} is the best response since at least one Rebel will play \textbf{stay}. 

Since the network is finite, if all players do not deviate, there is a finite time $t^{s}_{\theta}$ such that all Rebels play \textbf{revolt} forever if $\theta\in \{\theta: \#[Rebels](\theta)\geq k\}$; and there is a finite time $t^f_{\theta}$ such that all Rebels play \textbf{stay} forever if $\theta\in \{\theta: \#[Rebels](\theta)< k\}$. After $\max\{t^{s}_{\theta},t^f_{\theta}\}$, a Rebel who deviates at most get 0. However, if all Rebels do not deviate, all Rebels get $\max\{1,0\}$ after $\max\{t^{s}_{\theta},t^f_{\theta}\}$. Then, given a period $s>0$, a Rebel will not deviate if $\sum_{\theta:\#[Rebels](\theta)\geq k}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})>0$. This because, otherwise, he has a loss in his expected continuation payoff as $\delta^{t^s_{\theta}}\frac{\sum_{\theta:\#[Rebels](\theta)\geq k}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})}{1-\delta}$ after $t^s_{\theta}$. There is a $0<\delta<1$ to let such loss be large enough to impede Rebels deviations.

To check if $\tau^{*}$ and $\{\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})\}_{i\in N}$ satisfy full consistency\footnote{Krep and Wilson (1982)}, take any $0<\eta<1$ such that Rebels play $\tau^{*}$ with probability $1-\eta$, and play other behavior strategies with probability $\eta$. Clearly, when $\eta \rightarrow 0$, the belief converges to $\{\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})\}_{i\in N}$.
\end{proof}

\begin{remark}
Note that the first best cannot be attained in the equilibrium unless the network is complete. Consider the network in Example~\ref{ex_leading_ex}. Player 1's strategy is not contingent on the true state, and therefore players' actions in the first period are not ex-post efficient.   
\end{remark}



\section{Equilibrium: $k<n$}
\label{sec:equilibrium_2}


When $k<n$, the equilibrium construction for the $k=n$ case will not work. First, a Rebel still has incentive to play \textbf{revolt} even if there is an Inert neighbor. Second, an Inert never transmit additional information about relevant information since he has only one action. We then require more assumptions to get an APEX equilibrium. Example ~\ref{ex_strong_connectedness} shows why we need additional assumptions.

\begin{example}\label{ex_strong_connectedness}
Let $k=2$ and let the network as the following. Assume $\theta=(Rebel_1,Inert_2,Rebel_3)$.

\begin{center}
\begin{tikzpicture}[scale=1.5]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,0)/RB_1}, {(2,0)/2}, {(3,0)/RB_3}}
        \node[vertex] (\name) at \pos {$\name$};
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/2, 2/RB_3}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

First, since $k=2$, Rebel 1 has incentive to play \textbf{revolt} when $\pi(\{\theta:\theta_3=Rebel\})$ is high enough if Rebel 3 will play revolt . Second, Rebel 1 never learn $\theta_3$ since Inert 2 cannot reveal information about $\theta_3$. Thus, the game is reduced to an incomplete information game without communication. Clearly, an APEX equilibrium does not exist in this case.

\end{example}

In order to get an APEX equilibrium and to avoid the case of Example~\ref{ex_strong_connectedness}, I define \textit{Strong connectedness} and \textit{Full support on strong connectedness} as follows.

\begin{definition}
\textbf{Strong connectedness}: Given $G$, a state $\theta$ has strong connectedness if and only if for every pair of Rebels, there is a path consisting of Rebels to connect them.
\end{definition}  

\begin{definition}
\textbf{Full support on strong connectedness}: Given $G$, $\pi$ has full support on strong connectedness if and only if 
\[\pi(\theta)>0\Leftrightarrow \text{ $\theta$ has strong connectedness }\] 
\end{definition}  


The goal of this paper is to show that an APEX equilibrium always exists in the $k<n$ cases when the underlying network is without cycle. I define acyclic network in the following definition.
\begin{definition}
A network is without (with) cycles if and only if the path from $i$ to $j$, for all $i\neq j$, is (is not) unique. 
\end{definition}

I then state my main theorem as follows. 

\begin{theorem}
\label{thm_main_result}
For any $n$-person repeated $k$-Threshold game with parameter $k < n$ played in acyclic networks, if $\pi$ has full support on strong connectedness, then there is a $\delta^{*}$ such that an APEX equilibrium exists whenever $\delta>\delta^{*}$.
\end{theorem}

\subsection*{}
The equilibrium in Theorem ~\ref{thm_main_result} is constructive. I will construct the equilibrium path first, then construct the in-path and off-path beliefs, and then check whether or not there is a strategy profile extending equilibrium path and letting the belief system be consistent in every history to constitute an equilibrium. I begin with an overview of equilibrium construction, and then illustrate such construction. The whole equilibrium and the omitted proofs are in the Appendix~\ref{appx_network}.  

\subsection{Overview}

Given that the state has strong connectedness, Rebels have to find a ``language'' for communication. The construction of an APEX equilibrium is not trivial because the ``dimension'' of information is generally larger than the cardinality of their own action space. Rebels then use several sequences of actions to transmit information, and thus we have to track the belief updating in the time horizontal line and to check whether or not such sequences can constitute an equilibrium. To see that Rebels need to communicate with more dimensions of information, we may compare Example~\ref{ex_cycle_number_5} and Example~\ref{ex_cycle_number_6}.


\begin{example}\label{ex_cycle_number_5}
Let $k=5$ and let the network and the state $\theta$ be the following.

\begin{center} 
  \begin{tikzpicture}[scale=1]
    % First we draw the vertices
    \foreach \pos/\name in {{(2,1)/RB_1}, {(4,1)/RB_2}, {(1,2)/RB_3}, {(5,2)/RB_5}, {(3,3)/RB_7}, {(3,2)/4}, {(1,3)/6}, {(5,3)/8}, {(6,2)/9}, {(0,2)/10}}
        \node[vertex] (\name) at \pos {$\name$};
        
%        \foreach \pos/\name in {{(3,2)/4_L}, {(1,3)/6_L}, {(5,3)/8_L}, {(6,2)/9_L}, {(0,2)/10_L}}
%   \node[selected vertex] (\name) at \pos {$\name$};
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_2, RB_1/RB_3, RB_2/RB_5, RB_3/4, RB_3/6, RB_3/RB_7, 4/RB_5, RB_5/RB_7, RB_5/8, RB_5/9,6/RB_7, RB_7/8, RB_3/10}
        \path[edge] (\source) -- (\dest) ;
\end{tikzpicture}
\end{center} 

\end{example}


\begin{example}\label{ex_cycle_number_6}
Let $k=6$ and let the network and the state $\theta$ be the following.
\begin{center} 
  \begin{tikzpicture}[scale=1]
    % First we draw the vertices
    \foreach \pos/\name in {{(2,1)/RB_1}, {(4,1)/RB_2}, {(1,2)/RB_3}, {(5,2)/RB_5}, {(3,3)/7}, {(3,2)/4}, {(1,3)/6}, {(5,3)/8}, {(6,2)/RB_9}, {(0,2)/RB_{10}}}
        \node[vertex] (\name) at \pos {$\name$};
        
%        \foreach \pos/\name in {{(3,2)/4_L}, {(1,3)/6_L}, {(5,3)/8_L}, {(6,2)/9_L}, {(0,2)/10_L}}
%   \node[selected vertex] (\name) at \pos {$\name$};
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_2, RB_1/RB_3, RB_2/RB_5, RB_3/4, RB_3/6, RB_3/7, 4/RB_5, RB_5/7, RB_5/8, RB_5/RB_9,6/7, 7/8, RB_3/RB_{10}}
        \path[edge] (\source) -- (\dest) ;
\end{tikzpicture}
\end{center} 


\end{example}

In Example~\ref{ex_cycle_number_6}, there are 6 Rebels. On the contrary, there are 5 Rebels in Example~\ref{ex_cycle_number_5}. Suppose that we have a ``talking strategy'' as follows. Rebel 3 and Rebel 5 report the numbers of  Rebels in their neighborhood to Rebel 1 and Rebel 2. Rebel 1 and Rebel 2 then talk with each other about the total number of Rebels they have been informed conditional on Rebel 3 and Rebel 5's reporting. Conditional on the total number of Rebels they have been informed, Rebel 1 and Rebel 2 then initiate the coordination to play revolt or to play revolt. According to this talking strategy, however, Rebel 1 and Rebel 2 still do not know how many Rebels out there. This is because Rebel 3 and Rebel 5 report the same number of Rebel neighbors in both Example~\ref{ex_cycle_number_6} and Example~\ref{ex_cycle_number_5}. Thus, ``talking about how many nearby Rebels"  is not enough, Rebels have to ``talking about the locations of nearby Rebels''  in order to construct an APEX strategy. 

Moreover, in an APEX equilibrium path, \text{all} Rebels must tell whether or not there are more than $k$ Rebels in the equilibrium path at some timings. To see this, I give the following lemma.
\begin{lemma}\label{lemma_learn}
Given $G$, $\pi$, $\delta$, $k$. If a weak sequential equilibrium $\tau^*$ is APEX, then for all $\theta\in \Theta$, there is a finite time $T^{\theta}_i$ for a Rebel $i$ such that $\sum_{\theta:\#[Rebels](\theta)\geq k}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})$ either $=1$ or $=0$
whenever $s\geq T^{\theta}_i$.
\end{lemma}
The question is how to track each Rebel's timing in which he has known the relevant information. This higher-order belief is apparently an giant object in our private monitoring setting. To overcome the difficulty in tracking each Rebel's learning process, I let Rebels use several ``coordination sequences'' to communicate with others when they have known that some Rebels (including themselves) have known the relevant information.


In my construction, the off-path belief system gives the grim-trigger property. To be more precise, if a Rebel $i$ detects a deviation at period $s$, his off-path belief will be $\sum_{\theta \in \{\theta:\theta_j=Inert,j\notin G_i\}}\beta^{\pi,\tau}_{G_i}({\theta}|h^{s^{'}}_{G_i})=1$ for all $s^{'}\geq s$. I.e., he will believe that all players outside his neighborhood are Inerts, and therefore he will stop update his belief about relevant information. The consequence is that he will play \textbf{stay} forever if there are less than $k$ Rebel neighbors in his neighborhood. 

The equilibrium is constructed by three steps. I list these three steps in the following consecutive three subsections. In the first step, I define the \textit{information hierarchy} to specify which Rebels in $G$ have to report their information in the equilibrium path. In the second step, I construct the equilibrium path by using binary-$\{\textbf{revolt},\textbf{stay}\}$ sequences, and check the belief updating in the path. Finally, I use the grim-trigger-like off-path belief as a punishment schema to impede deviations in the third step.  

\subsection{Step 1. Information hierarchy in $G$}

The information hierarchy is defined on a network $G$ right after nature chooses a state. I will use the term ``node $i$'' instead of ``player $i$'' in this step. 

I define information hierarchy by defining $\{N^{-1}_i,N^{0}_i, N^{1}_i...\}$ and $\{I^{-1}_i,I^{0}_i, I^{1}_i...\}$ for each $i\in N$, and then define $\{\leq^0, \leq^1, \leq^2\}$ and $\{R^0,R^{1}, R^{2}...\}$ for each iteration in $(0,1,2,...)$. I also use the term ``blocks'' to represent the ``iterations''. 

Given $\theta$, the information hierarchy is defined as follows.
\begin{itemize}

\item \textbf{0-block}
Denote
\begin{eqnarray*}
N^{-1}_i &\equiv &  i \\
I^{-1}_i & \equiv & i
\end{eqnarray*}

Then define $R^0$ as 
\begin{equation}
R^0\equiv [Rebels](\theta)
\end{equation}

\item \textbf{1-block}
Denote
\begin{eqnarray*}
N^0_i &\equiv &  G_i \\
I^0_i & \equiv & G_i\cap R^0
\end{eqnarray*}

Define the set $\leq^0$ by defining
\begin{equation}i\in \leq^0 \Leftrightarrow \exists  j\in \bar{G}_i [I^0_i\subseteq N^0_j\cap R^0]\end{equation}  

Then define $R^1$ as 
\begin{equation}
R^{1} \equiv \{i\in R^0|i\notin \leq^0\}
\end{equation}

\item \textbf{$t+1$-block, $t\geq 1$}
Denote
\begin{eqnarray*}
N^t_i & \equiv & \bigcup_{k\in I^{t-1}_i}G_k \\
I^t_i & \equiv & \bigcup_{k\in G_i\cap R^t}I^{t-1}_k
\end{eqnarray*}


Define the set $\leq^t$ by defining
\begin{equation}i\in \leq^t \Leftrightarrow \exists j\in \bar{G}_i[I^t_i\subseteq N^t_j\cap R^0]\end{equation}

Then define $R^{t+1}$ as 
\begin{equation}
R^{t+1} \equiv  \{i\in R^t|i\notin \leq^t\}
\end{equation}


\end{itemize}

In other words, $i\in R^t$ if and only if \textit{(1)} $i$ is a Rebel and \textit{(2)} at $t$-block, there is a $j\in I^{t-1}_i$ who is a Rebel and whose existence is informed to $i$, but none of $i$'s neighbors has been informed that. Intuitively, the $R^t$ nodes then have more incentives to report their information to others. 

From the above definition, Theorem ~\ref{lemma_empty} states that it is sufficient to only let $R^t$ nodes to report their information if the underlying network is acyclic. 
\begin{theorem}
\label{lemma_empty}
If the network is acyclic and if the state has strong connectedness, then 
\[R^0\neq \emptyset \Rightarrow \exists t\geq 0[\exists i\in R^t[I^t_i=R^0]]\]
\end{theorem}



\subsection{Step 2: Equilibrium strategies in the path}


In this step, each player in $G$ is indexed with a distinguished prime number to indicate his ``location''. Such indexation is starting from $3$. To be more precise, I index each player $i$ as $x_i$, where $x_i\geq 3$ is a prime number. Since the multiplication of distinguish prime numbers can be uniquely factorized as those numbers, I then use this property to let Rebels be able to report both the amount and the locations of their Rebel neighbors by reporting the multiplication of their Rebel neighbors' prime numbers.

Denote $\langle\rangle$ as a form of sequence. Denote $|\langle\rangle|$ as the length of a form of finite sequence. Denote $\bar{N}\subset N$ as an non-empty subset of $N$. The notations for the forms of sequences are shown in Table ~\ref{Table_msg_form}. 

\begin{table}[t]
\caption{Notations}
\label{Table_msg_form}
\begin{center}
\begin{tabular}{l c c}
$\bar{N}$ 										& $\equiv$ 			& a non-empty subset of $N$  \\
$x_i$ 											& $\equiv$ 			& player $i$'s prime-number index  \\
$X_{\bar{N}}$ 								& $\equiv$ 			& $\prod_{j\in \bar{N}}x_j$  \\
\textbf{s}										& $\equiv$ 			& \textbf{stay}  \\
\textbf{r}										& $\equiv$ 			& \textbf{revolt}  \\
$\langle \textbf{stay} \rangle$ 		& $\equiv$ 			& $\langle \textbf{s},...,\textbf{s}\rangle$  \\
$\langle \textbf{revolt} \rangle$ 	& $\equiv$ 			& $\langle \textbf{r},...,\textbf{r}\rangle$  \\
$\langle  \bar{N} \rangle$ 				& $\equiv$ 			& $\langle \textbf{s},...,\textbf{s},\underbrace{\textbf{r},\textbf{s},...,\textbf{s}}_{X_{ \bar{N}}}\rangle$  \\

$\langle 1 \rangle$	 					& $\equiv$ 			& $\langle \textbf{s},...,\textbf{s},\underbrace{\textbf{r}}_{1}\rangle$  \\
$\langle x_i \rangle$	 	& $\equiv$ 			& $\langle \textbf{s},...,\textbf{s},\underbrace{\textbf{r},\textbf{s},...,\textbf{s}}_{x_i}\rangle$  \\
\end{tabular}
\end{center}
\end{table}

The $\langle\rangle$ and the $|\langle\rangle|$ will jointly determine the sequences of actions in the equilibrium path. For example, if a sequence takes the form $\langle 1 \rangle$ and its length $|\langle 1 \rangle|=3$, then this sequence is $\langle \textbf{s},\textbf{s},\textbf{r}\rangle$. Note that the length of a sequence is counted from its end.



In the equilibrium path, two phases, \textit{reporting period} and \textit{coordination period}, occur in turns finitely in the following way,
\[\underbrace{<\text{coordination period}>}_{0-block}\underbrace{<\text{reporting period}><\text{coordination period}>}_{1-block}...\]
I.e. after nature chooses a state, all the Rebels start with $0$-block, then enter to $1$-block,...,and so on. $0$-block has only one period, coordination period. The $t$-blocks, $t\geq 1$ has two periods, reporting period and coordination period, where reporting period occurs first and then coordination period follows. The length of each phase in each block is finite but endogenous.

If a sequence of actions is meant to be played in the reporting period (\textit{resp.} the coordination period), I called it a \textit{reporting message} (\textit{resp.} \textit{coordination message}). In reporting period in each $t$-block ($t\geq 1$), Rebels play the sequences defined in Table ~\ref{Table_msg_reporting}. In coordination period in each $t$-block ($t\geq 0$), Rebels play the sequences defined in Table ~\ref{Table_msg_coordination}. After the coordination period in each $t$-block ($t\geq 0$), players either \textit{(1)} start to repeatedly play some certain actions,  or \textit{(2)} enter to the reporting period in $t+1$-block. 


\subsubsection*{}
I start to give the details of reporting messages and coordination messages.


\subsubsection{Reporting messages in reporting period}

The reporting period in the $t$-block is denoted as $RP^t$. Denote $| RP^t |$ as the total number of periods in $RP^t$. In the equilibrium path, the sequence of actions played in the $RP^t$ is with length $| RP^t |$ and has to follow one kind of the forms listed Table ~\ref{Table_msg_reporting}. Any other sequence will be considered as a deviation. 

\begin{table}[ht]
\caption{Reporting messages}
\label{Table_msg_reporting}
\begin{center}
\begin{tabular}{c c }
Reporting Messages 		&   \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 	 \\
$\langle  {I^{t-1}_i} \rangle$ 		&   \\
$\langle 1 \rangle$ 		             &    
\end{tabular}
\end{center}
\end{table}

Table ~\ref{Table_blf_up_reporting} shows that the belief formed by Rebel $j$ after $j$ observe his neighbor $i$'s reporting messages in the equilibrium path.

\begin{table}[ht]
\caption{$j$'s belief updating after observing $i$'s reporting messages in the reporting period in $t$-block}
\label{Table_blf_up_reporting}
\begin{center}
\begin{tabular}{l c l}
$i$ plays 		&  			& the event that $j\in \bar{G}_i$ believes with probability one  \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 			    & $i\notin R^t$  \\
$\langle  {I^{t-1}_i} \rangle$ 		&  			& $i\in R^t$ and $l\in [Rebel](\theta)$ if $l\in I^{t-1}_i$      \\
$\langle 1 \rangle$ 		             &  			& $i\in R^t$ and $i$ has known $\#[Rebels](\theta)\geq k-1$ \\
\end{tabular}
\end{center}
\end{table}

According to Table ~\ref{Table_blf_up_reporting}, a Rebel can tell who are $R^t$ after reporting period. The consequence is that, if a Rebel $j$ has observed that all of his neighbors play $\langle  \textbf{stay} \rangle$, then he is sure that $\#[Rebels](\theta)< k$ if $\#I^{t-1}_j<k$\footnote{Remind that $R^t$ are those Rebels who have been informed the existence of some Rebels, but any of their neighbors has not been informed that.}. 

The important feature here is that a player may play a special sequence---$\langle 1 \rangle$---in the equilibrium path. This special sequence serve as a signal to indicate a \textit{pivotal player} in $RP^t$---a player who is certain that he will learn the the relevant information given others' truthful reporting right after $RP^t$. I elaborate this issue as follows.


\subsubsection*{Pivotal players in $RP^t$}
\begin{definition}[Pivotal players in $RP^t$]
Let $\theta\in \Theta$ be given. A player is pivotal in $RP^t$ if he is certain that he can tell whether or not $\#[Rebels](\theta)< k$ given others' truthful reporting right after $RP^t$.
\end{definition}
There are two kinds of pivotal players in $RP^t$. The first kind are those players who are certain that they can learn the true state. On the contrary, the second kind of pivotal players can only learn the relevant information.

For the first kind of pivotal players, we may consider the following two examples.

\begin{example} \label{ex_free_rider_tree}\textbf{Free Rider Problem}

Let $k=5$ and assume that there are message $\langle M_4 \rangle,\langle M_5 \rangle$ for Rebel 4, 5. To simply the analysis, let's assume that the game is played from $1$-block (by discarding the strategies in $0$-block and staring the game from the reporting period). Further, assume that Rebels will play \textbf{revolt} forever after observing that $\langle M_4 \rangle$ or $\langle M_5 \rangle$ is played once by Rebel 4 or 5 right after reporting period; otherwise they will play \textbf{stay} forever. Let $G$ be the following.

\begin{center}
\begin{tikzpicture}[scale=1]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,2)/RB_1}, {(2,1)/RB_2}, {(2,3)/3}, {(3,2)/RB_4}, {(4,2)/RB_5}, {(5,1)/6}, {(5,3)/7}, {(6,2)/RB_8}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_4, RB_2/RB_4,3/RB_4,RB_4/RB_5, RB_5/6, RB_5/7, RB_5/RB_8}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

Note that Rebel 4 and Rebel 5 are $R^1$ members. Let $\langle \rangle_4$ and $\langle \rangle_5$ be the sequences of actions they may use to report the number of Rebel neighbors. If Rebel 5 report truthfully, then Rebel 4 will not report truthfully by arranging the timings in which he plays \textbf{revolt}. Since Rebel 4 can use $\langle M_4 \rangle$ to initialize the coordination, such deviation is profitable. Same situation happens for Rebel 5, and then Rebel 4 and Rebel 5 will not report truthfully.

\end{example}

In the above example, two sources constitutes the free rider problem. One source is that there are coordination messages which will initiate coordination regardless how the reporting messages are played. The other source is that Rebel 4 and Rebel 5 are the pivotal players who can learn the true state. To see the later source more clearly, we may consider the following Example~\ref{ex_pivotal_1}.



\begin{example} \label{ex_pivotal_1}\textbf{Pivotal player: Case 1}
Let $k=6$ and suppose that there are message $\langle M_3 \rangle,\langle M_5 \rangle, \langle M_7 \rangle$ for Rebel 3,5,7 to initiate a coordination. Let the game be played from $1$-block as Example~\ref{ex_free_rider_tree}. Further, let's suppose that Rebels will play \textbf{revolt} forever after observing that $\langle M_3 \rangle$, $\langle M_5 \rangle$, or $\langle M_7 \rangle$ is played once in two periods right after this reporting period; otherwise they will play \textbf{stay} forever. Let $G$ be the following.
\begin{center}
\begin{tikzpicture}[scale=1]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,1)/RB_1}, {(1,3)/2}, {(2,2)/RB_3}, {(3,1)/4}, {(3,2)/RB_5}, {(3,3)/RB_6}, {(4,2)/RB_7}, {(5,1)/RB_8}, {(5,3)/9}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_3, 2/RB_3,RB_3/RB_5,4/RB_5, RB_6/RB_5, RB_5/RB_7, RB_7/RB_8, RB_7/9}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

Note that Rebel 3, 5, 7 are $R^1$ members. In contrast to Example~\ref{ex_free_rider_tree}, although Rebel 3, 7 can use their coordination messages to initiate coordination, they still have incentives to report truthfully. This is because they are not pivotal. Since the coordination to \textbf{revolt} has to be initiated immediately after this reporting period, they have incentives to report truthfully to Rebel 5.

Rebel 5, however, has no incentive to report truthfully since he is a pivotal player who can learn the true state.
\end{example}
   
From the discussions in Example~\ref{ex_free_rider_tree} and Example~\ref{ex_pivotal_1}, a way to deal with the free rider problem is to assign one of those pivotal players who constitute this problem as a \textit{free rider}. If the network is acyclic, Lemma ~\ref{lemma_at_most_two_nodes} shows that the free rider problem can be identified before the game enter to $RP^t$. To be more precise, first define $TR_{ij}$ to be a tree rooted in $i$ and spanning in $j\in \bar{G}_i$ as follows.
\begin{definition}
$TR_{ij}\equiv \{l\in N:\text{there is a unique path $\{l,...,j,i\}$ from $l$ to $i$ through $j$}\}$
\end{definition}
Then, define $C^t$ to be a set containing $R^t$ nodes such that, for all $i\in C^t$, there are no possible Rebel nodes connecting to $i$ by a path consisting of three or more nodes
\[C^t=\{i\in R^t:\nexists j\in R^{t-1}\cap \bar{G}_i[\exists l,l^{'}\in TR_{ij}[l\in N^{t-1}_j\backslash I^{t-1}_i \text{ and } l^{'}\in \bar{G}_l]]\}\]

In words, $C^1$ is the set of those nodes who can learn the true state right after $RP^t$. In Example~\ref{ex_free_rider_tree}, for instance, Rebel 4 and Rebel 5 are $C^1$ nodes. In Example~\ref{ex_pivotal_1}, Rebel 5  is a $C^1$ node. 

The following two lemmas are useful to identify the free rider problem in $RP^t$ before the game enters to $RP^t$. 

\begin{lemma}
\label{lemma_at_most_two_nodes}\footnote{Generally, this property does not hold if a network is cyclic.}
If the network is acyclic, and if the state has strong connectedness, then for each $t$-block, \[0\leq |C^t| \leq 2\]. Moreover, suppose there are two nodes in $C^t$, then they are each other's neighbor.
\end{lemma}
\begin{lemma}
\label{lemma_no_node_outside}
If the network is acyclic, and if the state has strong connectedness, then for each $t$-block
\[i\in C^t \Rightarrow \text{there is no possible Rebel node outside of }\bigcup_{k\in N^{t-1}_i}G_k\]
\end{lemma}

By Lemma ~\ref{lemma_at_most_two_nodes}, $C^t$ nodes are each other's neighbor (if there are two $C^t$ nodes). By Lemma ~\ref{lemma_no_node_outside}, it is straightforward to show that $C^t$ nodes can identify themselves.\footnote{To be more precise, they identify themselves by the following procedure. First, a $C^t$ node, $j$, assumes that one of his $R^{t-1}$ neighbor, $i$, is a $R^t$-node. Second, he check if $i$ is in $C^t$ by checking the definition of $C^t$. Third, if $i$ is identified as a $C^t$ node, $i$ is the only $C^t$ node other than $j$ (by Lemma ~\ref{lemma_at_most_two_nodes}). Finally, $j$ assumes that $i$ will do the same procedure to identify him. Since $j$ himself is a $C^t$-node, $i$ must be able to identify him if $i$ is a $C^t$-node, and thus both $C^t$-nodes $i$ and $j$ can identify each other.} In order to solve the free rider problem in which there are multiple $C^t$ nodes in $RP^t$, we can let the node in $C^t$ who has smallest prime index to be the free rider, and then solve the problem.

For the second kind of pivotal players, who can only learn the relevant information right after $RP^t$, we may consider the following example.

\begin{example} \label{ex_pivotal_2}\textbf{Pivotal player: Case 2}
Let $k=6$. Again, assume that there are coordination message $\langle M\rangle$s for Rebels. Let the game be played from $1$-block as Example~\ref{ex_free_rider_tree}. Let's assume that Rebels will play \textbf{revolt} forever after observing that $\langle M \rangle$ is played once in four periods right after reporting period; otherwise they will play \textbf{stay} forever. 

Let $G$ be the following.

\begin{center}
\begin{tikzpicture}[scale=1.2]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(2,2)/RB_1}, {(2,1)/RB_2}, {(2,3)/RB_3}, {(3,2)/RB_4}, {(4,2)/RB_5}, {(5,2)/RB_6}, {(6,2)/RB_7}, {(7,2)/8}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_4, RB_2/RB_4,RB_3/RB_4,RB_4/RB_5, RB_5/RB_6, RB_6/RB_7, RB_7/8}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

In this case, there is no Rebel in $C^1$. Rebel 4, nevertheless, will deviate from reporting $\langle I^0_4 \rangle$. Note that Rebel 4 has already known there are 5 Rebels in this world, and therefore he knows that the coordination to \textbf{revolt} can be initiated by him  if he is informed the existence of one more Rebels. Moreover, if no more Rebels exist, coordination to \textbf{stay} can be also initiated by him. Since he can use the message $\langle M \rangle$ to initiate the coordination, his deviation is profitable given others' truthful reporting.
\end{example}

In a summary, the sequence $\langle 1 \rangle$ is introduced in order to let the pivotal players ``identify'' themselves. In the Appendix~\ref{appx_network_equilibrium}, i can show that the pivotal players in $RP^t$ are those Rebels who are either $C^t$ nodes or have already known there are $k-1$ Rebels in the equilibrium path. The equilibrium construction will enforce the pivotal players to play $\langle 1 \rangle$ in the equilibrium path, and therefore the belief updating after observing $\langle 1 \rangle$  is as Table ~\ref{Table_blf_up_reporting} shows.




\subsubsection{Coordination messages in coordination period}

The ignorance of previous reporting messages after observing a coordination message $\langle M \rangle$ may incur untruthful reporting as the above Example~\ref{ex_free_rider_tree}, ~\ref{ex_pivotal_1}, and ~\ref{ex_pivotal_2} show. The sequence $\langle 1 \rangle$ is introduced in order to tackle this issue. However, one may have observed that the concatenation of these two messages, $\langle 1 \rangle\langle M \rangle$,  is another coordination message itself. To be more precise, $\langle\langle \textbf{s}, \textbf{r} \rangle\langle M \rangle\rangle$ is another coordination message by truncating previous actions in $\langle 1 \rangle$ and concatenating the remaining actions to $\langle M \rangle$. If players' continuation behaviors after they observe $\langle\langle \textbf{s}, \textbf{r} \rangle\langle M \rangle\rangle$ are independent from the previous reporting messages, then the issue of untruthful reporting is not solved. 

In this section, I discuss the coordination messages. And in the equilibrium construction, I let players' belief updating be contingent not only on the coordination messages but also on the previous reporting messages in the equilibrium path.


I depict the ``structure'' in the coordination period. There are three divisions in coordination period and there are several sub-blocks in each division. In $t=0$ block, the structure is
\[\overbrace{\langle\underbrace{\langle \cdot \rangle }_{\text{$1$ sub-block}}\rangle}^{\text{1st division}} \overbrace{\langle\underbrace{\langle \cdot \rangle }_{\text{$1$ sub-blocks}} \rangle}^{\text{2nd division}} \overbrace{\langle\underbrace{\langle \cdot \rangle \cdot \cdot \cdot \langle \cdot \rangle}_{\text{$n$ sub-blocks}}\rangle}^{\text{3rd division}}\] 
; in $t>0$ blocks, the structure is
\[\overbrace{\langle\underbrace{\langle \cdot \rangle \cdot \cdot \cdot \langle \cdot \rangle}_{\text{$n$ sub-blocks}}\rangle}^{\text{1st division}} \overbrace{\langle\underbrace{\langle \cdot \rangle \cdot \cdot \cdot \langle \cdot \rangle}_{\text{$t+1$ sub-blocks}} \rangle}^{\text{2nd division}} \overbrace{\langle\underbrace{\langle \cdot \rangle \cdot \cdot \cdot \langle \cdot \rangle}_{\text{$n$ sub-blocks}}\rangle}^{\text{3rd division}}\] 
, where $n=\# N$. 


In the $t$-block, denote $CD^t_{m,q}$ as the $m$ sub-block in $q$ division and denote $| CD^t_{m,q} |$ as the total number of periods in $CD^t_{m,q}$.  The sequence of actions in equilibrium path takes the following forms of sequences with length $| CD^t_{m,q} |$ as Table ~\ref{Table_msg_coordination} shows.
\begin{table}[ht]
\caption{Coordination messages}
\label{Table_msg_coordination}
\begin{center}

\begin{tabular}{cc }
Coordination messages		&   \\
\hline
$\langle x_i \rangle$ 	& 	 \\
$\langle \textbf{stay} \rangle$	&   \\
\textbf{r}									& 	\\
\textbf{s}									& 	\\
\end{tabular}
\end{center}
\end{table}

Since the $0$-block has simpler structure, I will focus on introducing players' behaviors in the coordination period in $t>0$ block in the following paragraphs, while the Appendix~\ref{appx_network_equilibrium} shows the equilibrium path in $t=0$ block\footnote{By equilibrium construction, all Rebels will play \textbf{revolt} after $0$-block in the equilibrium path if there is a Rebel who has at least $k$ Rebels neighbors. }. 

\subsubsection*{The equilibrium path in $(CD^t_{1,1},...,CD^t_{n,1})$, $t>0$}
Table ~\ref{Table_blf_up_cdt11} shows the belief updating formed by a Rebel $j$ after he observes $i$'s behavior after $CD^t_{1,1}$ in the equilibrium path. According to Table ~\ref{Table_blf_up_cdt11}, Rebel $j$ can tell whether or not $\#[Rebels](\theta)< k$ after $CD^t_{1,1}$ for some $t>0$-block. As Table ~\ref{Table_stg_cdt21} and Table ~\ref{Table_stg_cdtm1} show, in order to transmit the information about whether or not they have learn $\#[Rebels](\theta)< k$, Rebels will play $\langle x_i \rangle$ unless they observe  $\langle \textbf{stay} \rangle$ in $CD^t_{2,1}$ to $CD^t_{n,1}$.   The information about $\#[Rebels](\theta)< k$ will then be transmitted across all players after $CD^t_{n,1}$, . 

Note that a Rebel $j$ will play \textbf{stay} forever if he believes that $\#[Rebels](\theta)< k$ is with probability one. Thus, the sequence $\langle \textbf{stay} \rangle$ played in $CD^t_{1,1}$ to $CD^t_{n,1}$ is interpreted as the coordination message to initiate the coordination to \textbf{stay}.

\begin{table}[ht]
\caption{$j$'s belief updating after $CD^t_{1,1}$ by observing $i$'s previous actions  ($t>0$)}
\label{Table_blf_up_cdt11}
\begin{center}
\begin{tabular}{c c c}
In $RP^t$ 	&  	In $CD^t_{1,1}$		&  \\
\hline
\hline
$i$ plays 		&  	$i$ plays		& The events that $j\in \bar{G}_i$ believe with probability one  \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 	$\langle x_i \rangle$	    & $i\notin R^t$ \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle \textbf{stay} \rangle$		& $\#[Rebels](\theta)< k$     \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$		& $i\in R^t$     \\
$\langle 1 \rangle$ 		             &  $\langle \textbf{stay} \rangle$		& $\#[Rebels](\theta)< k$  \\
$\langle 1 \rangle$ 		             &  $\langle x_i \rangle$		&  $\#[Rebels](\theta)\geq k$ 
\end{tabular}
\end{center}
\end{table}



\begin{table}[ht]
\caption{In-path strategies in $RP^t$, $CD^t_{1,1}$, and $CD^t_{2,1}$ ($t>0$)}
\label{Table_stg_cdt21}
\begin{center}
\begin{tabular}{c c c}
In $RP^t$ 	 	&  	In $CD^t_{1,1}$		&  In $CD^t_{2,1}$	\\
\hline
\hline
$i$ plays 		  							&  	$i$ plays									& $j\in \bar{G}_{i}$ plays  \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 	$\langle x_i \rangle$	    & $\langle x_i \rangle$ \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle \textbf{stay} \rangle$		& $\langle \textbf{stay} \rangle$     \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$		& $\langle x_i \rangle$     \\
$\langle 1 \rangle$ 		             &  $\langle \textbf{stay} \rangle$		& $\langle \textbf{stay} \rangle$  \\
$\langle 1 \rangle$ 		             &  $\langle x_i \rangle$		&  $\langle x_i \rangle$  
\end{tabular}
\end{center}
\end{table}

\begin{table}[ht]
\caption{In-path strategies in $CD^t_{m,1}$, where $m\geq 2$ ($t>0$)}
\label{Table_stg_cdtm1}
\begin{center}
\begin{tabular}{c c c}
In $CD^t_{m,1}$, $m\geq 2$ 	 	&  	In $CD^t_{m+1,1}$,$m\geq 2$		& 	\\
\hline
\hline
$i$ plays 		  							&  $j\in \bar{G}_{i}$ plays  								& \\
\hline
$\langle x_i \rangle$ 	& 	$\langle x_i \rangle$	    &  \\
$\langle \textbf{stay} \rangle$		&  $\langle \textbf{stay} \rangle$	&  \\

\end{tabular}
\end{center}
\end{table}


\subsubsection*{The equilibrium path in $(CD^t_{1,2},...,CD^t_{t+1,2})$, given $t>0$}
After $CD^t_{n,1}$ and in $CD^t_{1,2}$, Rebels start to check if the coordination to \textbf{revolt} can be initiated. The coordination message to initiate the coordination to \textbf{revolt} is $\langle \textbf{stay} \rangle$ as Table ~\ref{Table_blf_up_cdt12} shows. The key feature here is that $\langle \textbf{stay} \rangle$ is a coordination message to initiate the coordination to \textbf{revolt} \textit{only if} $\langle  {I^{t-1}_i} \rangle$ or $\langle 1 \rangle$ has been played in $RP^t$\footnote{Although $\langle \textbf{stay} \rangle$ is also the coordination message to initiate the coordination to \textbf{stay} in $CD^t_{1,1}$ to $CD^t_{n,1}$, Rebels are not confused about it.}. Although this sequence incurs no expected cost, initiating the coordination to \textbf{revolt} by this sequence is ``not free'' since it requires the Rebels to play \textbf{revolt} in the previous reporting period in order to initiate the coordination to \textbf{revolt}. Since the highest continuation payoff contingent on $\theta\in\{\theta:\#[Rebels](\theta)\geq k\}$ is the coordination to \textbf{revolt}, players then have incentive to play \textbf{revolt} in the previous reporting period.



After $CD^t_{1,2}$, and from $CD^t_{2,2}$ to $CD^t_{t+1,2}$, Rebels start to transmit the information about whether or not they have learn that $\#[Rebels](\theta)\geq k$. According to Table ~\ref{Table_stg_cdt12} and Table ~\ref{Table_stg_cdtm2}, they will play $\langle \textbf{stay} \rangle$ unless they observe someone play $\langle x_i \rangle$. After $CD^t_{{t+1},1}$, the information about $\#[Rebels](\theta)\geq k$ will be transmitted across at least $k$ Rebels. 

\begin{table}[ht]
\caption{$j$'s belief updating after $CD^t_{1,2}$ by observing $i$'s previous actions  ($t>0$)}
\label{Table_blf_up_cdt12}
\begin{center}
\begin{tabular}{l c c c}
In $RP^t$ 	 	&  	In $CD^t_{1,1}$		&  In $CD^t_{1,2}$	  &\\
\hline
\hline
$i$ plays 		                             &  	$i$ plays		&				$i$ plays			& The events $j$ believe with probability one  \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 	$\langle x_i \rangle$	&  $\langle \textbf{stay} \rangle$ &  $i\notin R^t$ \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle \textbf{stay} \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\#[Rebels](\theta)< k$   \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\#[Rebels](\theta)\geq k$    \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$	&	$\langle x_i \rangle$ &  $i\in R^t$  \\
$\langle 1 \rangle$ 		             &  $\langle \textbf{stay} \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\#[Rebels](\theta)< k$\\
$\langle 1 \rangle$ 		             &  $\langle x_i \rangle$	&	$\langle \textbf{stay} \rangle$ & $\#[Rebels](\theta)\geq k$
\end{tabular}
\end{center}
\end{table}




\begin{table}[ht]
\caption{In-path strategies in $RP^t$, $CD^t_{1,1}$, $CD^t_{1,2}$, and $CD^t_{2,2}$ ($t>0$)}
\label{Table_stg_cdt12}
\begin{center}
\begin{tabular}{l c c c}
In $RP^t$ 	 	&  	In $CD^t_{1,1}$		&  In $CD^t_{1,2}$	  & In $CD^t_{2,2}$ \\
\hline
\hline
$i$ plays 		                             &  	$i$ plays		&				$i$ plays			& $j\in \bar{G}_i$ plays  \\
\hline
$\langle  \textbf{stay} \rangle$ 	& 	$\langle x_i \rangle$	&  $\langle \textbf{stay} \rangle$ &  $\langle \textbf{stay} \rangle$ \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle \textbf{stay} \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\langle \textbf{stay} \rangle$   \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\langle x_i \rangle$    \\
$\langle  {I^{t-1}_i} \rangle$ 		&  $\langle x_i \rangle$	&	$\langle x_i \rangle$ &  $\langle \textbf{stay} \rangle$  \\
$\langle 1 \rangle$ 		             &  $\langle \textbf{stay} \rangle$	&	$\langle \textbf{stay} \rangle$ &  $\langle \textbf{stay} \rangle$\\
$\langle 1 \rangle$ 		             &  $\langle x_i \rangle$	&	$\langle \textbf{stay} \rangle$ & $\langle x_i \rangle$
\end{tabular}
\end{center}
\end{table}

\begin{table}[ht]
\caption{In-path strategies in $CD^t_{m,2}$, where $m\geq 2$ ($t>0$)}
\label{Table_stg_cdtm2}
\begin{center}
\begin{tabular}{c c c}
In $CD^t_{m,2}$, $m\geq 2$ 	 	&  	In $CD^t_{m+1,2}$,$m\geq 2$		& 	\\
\hline
\hline
$i$ plays 		  							&  $j\in \bar{G}_{i}$ plays  								& \\
\hline
$\langle x_i \rangle$ 	& 	$\langle x_i \rangle$	    &  \\
$\langle \textbf{stay} \rangle$		&  $\langle \textbf{stay} \rangle$	&  \\

\end{tabular}
\end{center}
\end{table}




\subsubsection*{The equilibrium path in $(CD^t_{1,3},...,CD^t_{n,3})$, given $t>0$}

The game finally enters to $CD^t_{1,3}$. In this period, those $k$ Rebels who have learn that $\#[Rebels](\theta)\geq k$ will start to play \textbf{revolt} forever. Furthermore, this is the first period in which a Rebel may get positive expected payoff by playing \textbf{revolt} (in the equilibrium path). From $CD^t_{2,3}$ to $CD^t_{n,3}$, other Rebels start to transmit this information to all Rebels in order to coordinate to \textbf{revolt}.  Table ~\ref{Table_stg_cdm3} shows players' behavior from $CD^t_{2,3}$ to $CD^t_{n,3}$.

\begin{table}[ht]
\caption{In-path strategies in $CD^t_{1,3}$, $t>0$}
\label{Table_stg_cd13}
\begin{center}
\begin{tabular}{c c c}
In $CD^t_{m,2}$, $1\leq m\leq t+1$ 	 	&  	In $CD^t_{1,3}$		& 	\\
\hline
\hline
$i$ has played 		  							&  $j\in \bar{G}_{i}$ plays  								& \\
\hline
$\langle x_i \rangle$ 	& 	\textbf{r}	    &  \\
Otherwise		&  \textbf{s}	&  \\

\end{tabular}
\caption{In-path strategies after $CD^t_{m,3}$, where $m\geq 2$, $t>0$}
\label{Table_stg_cdm3}
\end{center}
\end{table}

\begin{table}[ht]
\begin{center}
\begin{tabular}{c c c}
In $CD^t_{m,3}$, $m\geq 2$ 	 	&  	In $CD^t_{m+1,3}$, $m\geq 2$		& 	\\
\hline
\hline
$i$ plays 		  							&  $j\in \bar{G}_{i}$ plays  								& \\
\hline
\textbf{r} 	& 	\textbf{r}	    &  \\
\textbf{s}		&  \textbf{s}	&  \\

\end{tabular}
\end{center}
\end{table}



\subsection{Step 3: Off-path Belief}

Whenever Rebel $i$ detects a deviation at period $s$, he forms the following belief: 
\begin{equation}
\label{eq_grim_trigger}
\sum_{\theta \in \{\theta:\theta_j=Inert,j\notin G_i\}}\beta^{\pi,\tau}_{G_i}({\theta}|h^{s^{'}}_{G_i})=1 \text{, for all $s^{'}\geq s$}
\end{equation}
. Thus, if $\# I^0_i<k$, he will play \textbf{stay} forever. This off-path belief serves as a grim trigger. 



\subsection{Sketch of the proof for Theorem ~\ref{thm_main_result}}

I have listed Rebels' behavior and their belief updating in my constructed equilibrium path in Table ~\ref{Table_blf_up_reporting}, Table~\ref{Table_blf_up_cdt11}, and Table~\ref{Table_blf_up_cdt12}. The following lemma shows that such equilibrium path is APEX.
\begin{lemma}\label{lemma_in_the_path}
For any $n$-person repeated $k$-Threshold game with parameter $k\leq n$ played in an acyclic network, if $\pi$ has full support on strong connectedness, then there exists an equilibrium path that is APEX.
\end{lemma}

I sketech the proof for Theorem ~\ref{thm_main_result} as follows. First, I use off-path belief to prevent players from making detectable deviations, such as deviating from playing the specified forms of sequences that are listed in Table ~\ref{Table_msg_reporting} or ~\ref{Table_msg_coordination}. Then I argue that any undetectable deviation made by a Rebel before he learns the relevant information, $\#[Rebels](\theta)\geq k$ or $\#[Rebels](\theta)< k$, will reduce his own expected continuation payoff.  To see this, we may consider the case in which a Rebel wants to mimic pivotal plays' behaviors by sending $\langle 1 \rangle$ in a reporting period. According to Table ~\ref{Table_blf_up_cdt11} and Table ~\ref{Table_blf_up_cdt12}, his neighbors' continuation playing after observing $\langle 1 \rangle$ is to play \textbf{stay} forever or to play \textbf{revolt} forever. But then all of his neighbors will repeat the same action afterward, and hence he cannot get more information to tell whether or not $\#[Rebels](\theta)< k$. When $\delta$ is high enough,  he can get better continuation payoff by staying in the path in which he can learn the relevant information (by Lemma ~\ref{lemma_learn}). To be more precise, by staying in the path, his static payoff eventually achieves the maximum static payoff as 1 when $\#[Rebels](\theta)\geq k$, and achieves the maximum static payoff as 0 when $\#[Rebels](\theta)< k$ \footnote{Claim ~\ref{claim_can_not_pretend_almost_success} in the Appendix~\ref{appx_network_equilibrium} shows this argument}.

\subsection{Discussion}
\label{sec:varies}


\subsubsection{Variation: payoff as signals}
The hidden payoff assumption can be relaxed without change the main result. One may consider a situation in which the static payoff not only depends on players' joint efforts but also on some  random shocks, says the weather.\footnote{e.g.,\citep{SHADMEHR2011}}. To be more precise, there is a public signal $y\in \{y_1,y_2\}$ generated by Rebels' actions. Let Rebel $i$'s payoff function be $u_{Rebel}(a_{Rebel_i},y)$, and let $u_{Rebel}(\textbf{stay},y_1)=u_{Rebel}(\textbf{stay},y_2)=u_0$. The distribution of $y_1$ and $y_2$ is 
\begin{eqnarray*}
p_{1s} &=& \mathrm {Pr}(y=y_1|\#\textbf{revolt}\geq k) \\
p_{1f} &=& \mathrm {Pr}(y=y_1|\#\textbf{revolt}< k) \\
p_{2s} &=& \mathrm {Pr}(y=y_2|\#\textbf{revolt}\geq k) \\
p_{2f} &=& \mathrm {Pr}(y=y_2|\#\textbf{revolt}< k) 
\end{eqnarray*}
such that
\begin{equation}
p_{1s}u_{Rebel}(\textbf{revolt}, y_1)+p_{2s}u_{Rebel}(\textbf{revolt}, y_2)>u_0>p_{1f}u_{Rebel}(\textbf{revolt}, y_1)+p_{2f}u_{Rebel}(\textbf{revolt}, y_2) \label{eqn_network_6}
\end{equation}
and
\begin{equation}
1>p_{1s}>0,1>p_{2s}>0,p_{1f}=1-p_{1s},p_{2f}=1-p_{2s} \label{eqn_network_7}
\end{equation}

Equation~\ref{eqn_network_6} is a generalization of the $k$-threshold game. Equation~\ref{eqn_network_7} is a full support assumption on signal $y$. 

If Equation~\ref{eqn_network_7} holds, we can construct exactly the same equilibrium strategy by ignoring the noisy signal $y$. To see this, we can check the equilibrium path constructed in the previous sections. According to Table ~\ref{Table_msg_reporting} and Table ~\ref{Table_msg_coordination}, given a period $s$ before some Rebels play $\langle 1 \rangle$, there is at most one Rebel who plays action \textbf{revolt}. Since that, the signal $y$ is not relevant before some Rebels play $\langle 1 \rangle$.  We then check if a Rebel wants to play $\langle 1 \rangle$ in order to get additional information coming from $y$.  However,  playing $\langle 1 \rangle$ will initiate either the coordination to \textbf{stay} or the coordination to \textbf{revolt} as Table ~\ref{Table_blf_up_cdt11} and Table ~\ref{Table_blf_up_cdt12} shows. After a coordination is initiated, a Rebel can not get additional information to learn the relevant information. This is because the signal $y$ is noisy, and Rebels' actions will repeat. By the same argument in Claim ~\ref{claim_can_not_pretend_almost_success} (in the Appendix~\ref{appx_network_equilibrium}), a Rebel is better to stay in the equilibrium path.

If Equation~\ref{eqn_network_7} does not hold, says $p_{1s}=p_{2f}=1$, then the signal $y$ is not noisy, and therefore the strategies constructed in the previous section is no longer an equilibrium. However, another APEX equilibrium can be constructed by letting all Rebels play \textbf{revolt} in the first period, and then keep playing \textbf{revolt} or \textbf{stay} contingent on the signals $y=y_1$ or $y=y_2$.

\subsubsection{Variation: Rebels with different levels of efforts}

We may also consider a model in which players contribute different levels of efforts to a collective action. Let the set of states of nature be $\hat{\Theta}=\Theta \times \Xi$, where $\Theta=\{Rebel,Inert\}^n$ and $\Xi=\{1,2,...,k\}^n$. Let $\hat{\theta}=(\theta,e)$ be a state of nature. After $\hat{\theta}$ is realized, a player $i$ will hold an endowment $e_i$, where $e_i\in \{1,2,...,k\}$. The payoff structure is modified as the following.
\begin{enumerate}
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=b_i$ if $a_{Rebel_i}=\textbf{revolt}$ and $\sum_{j:a_{\theta_j}=\textbf{revolt}}e_j\geq k$
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=-e_i$ if $a_{Rebel_i}=\textbf{revolt}$ and $\sum_{j:a_{\theta_j}=\textbf{revolt}}e_j< k$
\item $u_{Rebel_i}(a_{Rebel_i},a_{-\theta_i})=0$ if $a_{Rebel_i}=\textbf{stay}$
\item $u_{Inert_i}(a_{Inert_i},a_{-\theta_i})=1$ if $a_{Inert_i}=\textbf{stay}$
\end{enumerate}



After $\hat{\theta}$ is realized, players repeatedly play the above game in a network $G$. To see that the strategies constructed in previous section is still an equilibrium, we can transform $(G,\hat{\Theta})$ to $(G^{'},\hat{\Theta}^{'})$, where each player $i$ is attached with $\#e_i$ different players in $G^{'}$, and $\hat{\Theta}^{'}=\Theta\times \{1\}^{n}$. 


\subsubsection{Variation: networks with cycles}

The prime indexing can deal with potential free problems when players play the repeated $k$-threshold game in a cyclic network. We may consider the following example.

\begin{example}
\label{ex_no_free_rider_cycle}
Let $k=6$ and let $\theta$ and $G$ be the following. In this network, Rebel 3 and Rebel 4 have the same information $I^1_3=I^1_4$. If there is no punishment, Rebel 3 (or Rebel 4) may shirk and deviate from truthfully reporting $\langle I^3 \rangle$ (or $\langle I^4 \rangle$) at a reporting period if Rebel 4 (or Rebel 3) can reports truthfully. But this kind of deviation can be detected by Rebel 5 (or Rebel 2) since $I^1_3$ should be equal to $I^1_4$. 

\begin{center}
\begin{tikzpicture}[scale=1.5]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,2)/RB_1}, {(2,2)/RB_2}, {(3,1.5)/RB_3}, {(3,2.5)/RB_4}, {(4,2)/RB_5}, {(5,2)/RB_6}, {(6,2)/7}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in {RB_1/RB_2, RB_2/RB_3,RB_2/RB_4,RB_3/RB_5, RB_4/RB_5, RB_5/RB_6, 7/RB_6, RB_4/RB_3}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

\end{example}

However, there is another free rider problem that is hard to solve. Remind that, when the network is acrylic, the free rider problem is solved by selecting a player as a free rider before the game enters to the reporting period. In cyclic network, we may need more elaborations to select a free rider to solve the free rider problem. Let's consider the Example ~\ref{ex_free_rider_cycle}.
\begin{example}\label{ex_free_rider_cycle}
Let $k=6$. Suppose the network and $\theta$ is as follows. 

\begin{center}
\begin{tikzpicture}[scale=1]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,3)/1}, {(2,3)/RB_2}, {(4,3)/3}, {(6,3)/RB_4}, {(7,3)/5}, {(3,2)/RB_6}, {(5,2)/RB_7}, {(3,4)/RB_8}, {(5,4)/RB_9}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in { 1/RB_6, 1/RB_8, RB_2/3, RB_2/RB_8, 3/RB_4, RB_2/RB_6, RB_6/RB_7, RB_8/RB_9, RB_9/RB_4, RB_7/RB_4, RB_9/5, RB_7/5}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

Let's assume that players follow the equilibrium path constructed in the previous section, and assume that they are in the end of $1$-block. In such case, Rebel 2 has been informed that $I^1_2=\{RB_2,RB_6,RB_8,RB_9,RB_7\}$, Rebel 4 has been informed that $I^1_4=\{RB_4,RB_7,RB_9,RB_8,RB_6\}$, and so on. One more round of reporting period will let Rebels 2,6,7,4,9,8 know the true state $\theta$, and therefore Rebels 2,6,7,4,9,8 are all pivotal players who constitute a free rider problem (as Example ~\ref{ex_free_rider_tree}). We may select a player to be a free rider, says Rebel 4 is selected, before the game enters to the reporting period in $2$-block. However, this selection is ex-post. From the point of players' view, the state could be $\theta^{'}$ as the following.

\begin{center}
\begin{tikzpicture}[scale=1]
    % Draw a 7,11 network
    % First we draw the vertices
    \foreach \pos/\name in {{(1,3)/1}, {(2,3)/RB_2}, {(4,3)/3}, {(6,3)/4}, {(7,3)/RB_5}, {(3,2)/RB_6}, {(5,2)/RB_7}, {(3,4)/RB_8}, {(5,4)/RB_9}}
        \node[vertex] (\name) at \pos {$\name$};
    
    
    % Connect vertices with edges 
    \foreach \source/ \dest in { 1/RB_6, 1/RB_8, RB_2/3, RB_2/RB_8, 3/4, RB_2/RB_6, RB_6/RB_7, RB_8/RB_9, RB_9/4, RB_7/4, RB_9/RB_5, RB_7/RB_5}
        \path[edge] (\source) -- (\dest) ;
        
\end{tikzpicture}
\end{center}

In $\theta^{'}$, player 4 is an Inert and therefore not a pivotal Rebel, and hence he can not be selected as a free rider. We then need another rule in order to select a free rider during the game is played in the reporting period in the $2$-block. 
\end{example}

As Example ~\ref{ex_free_rider_tree} or Example~\ref{ex_free_rider_cycle} show, free rider problems occur if a free rider has not yet been selected before the game enter to a reporting period. In cyclic networks, this problem become more difficult to solve. Unfortunately, the solution is still infeasible in this paper. 

I leave a conjecture in this paper and end this section.

\begin{conjecture}
For any $n$-person repeated $k$-Threshold game with parameter $ k < n$ played in any network,
if $\pi$ has full support on strong connectedness, then there exists a $\delta^{*}$ such that an APEX equilibrium exists whenever $\delta>\delta^{*}$.
\end{conjecture}



\section{Conclusion}
\label{sec:con}

I model a coordination game and illustrate the learning processes generated by strategies in a sequential equilibrium and answer the question proposed in the beginning: what kind of networks can conduct coordination in a collective action game with information barrier. In the equilibrium, players transmit the relevant information by encoding such information by their actions in the time horizontal line. Since there is an expected cost in coding information, potential free rider problems may occur to impede the learning process. When the networks are without cycle, players can always learn the underlying relevant information and conduct the coordination only by their actions. However, what kinds of equilibrium strategies can constitute a learning process to learn the relevant information in cyclic networks still remains to be answered.


The construction of communication protocol exploits the assumption of finite type space and the finite threshold. Since the relevant information has been parameterized as a threshold, players can acquire this information by jointly incrementally reporting their own private information. The major punishment to keep players staying in the equilibrium path is then the joint shifting to play same actions as the stopping to update their information. The threshold model seems a general model in proofing that a communication protocol not only leads a learning process but also constitutes an equilibrium to reveal the relevant information in finite time.

Existing literatures in political science and sociology have recognized the importance of social network in influencing individual's behavior in participating social movements, e.g., \citep{Passy2003}\citep{McAdam2003}\citep{Siegel2009}. This paper views networks as routes for communication where rational individuals initially have local information, and they can influence nearby individuals by taking actions. Such influence may take long time to travel across individuals, and the whole process incurs inefficient outcomes in many periods. A characterization in the speed of information transmission across a network is not answered here, although it is an important topic in order to give more attentions in investigating the most efficient way to let the information be spread . This question would remain for the future research.



\bibliographystyle{abbrvnat}	% (uses file "plain.bst")
\bibliography{bigref}		% expects file "myrefs.bib"


\appendix
\section{Appendix}
\label{appx_network}
\noindent\textbf{proof for Lemma ~\ref{lemma_learn}}

\begin{proof}
The proof is done by contradiction. Suppose Rebels' strategies constitute an APEX. By definition of APEX, there is a time $T^{\theta}$ when actions start to repeat at state $\theta$. Let $T=\max_{\theta\in \Theta}{T^{\theta}}$. Pick that time $T_i=T+1$ and suppose the consequence did not not holds so that $0<\sum_{\theta:\#[Rebels](\theta)\geq k}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{s}_{G_i})<1$ for some $s\geq T_i$. Then this Rebel puts some positive weights on some $\theta\in \{\theta:\#[Rebels](\theta)< k\}$ and puts some positive weights on $\theta\in \{\theta:\#[Rebels](\theta)\geq k\}$ at that time $s$. Note this Rebel $i$ has already known $\theta_j$ if $j\in G_i$, and therefore Rebel $i$ put some positive weights on $\theta\in \{\theta:\#[Rebels](\theta)< k, \theta_l=Rebel, l\notin G_i\}$ and $\theta\in \{\theta:\#[Rebels](\theta)< k, \theta_l=Inert, l\notin G_i\}$. Since actions start to repeat at $T$, all $i$'s neighbors will play the same actions as the actions at time $T$, but then Rebel $i$ can not update information from his neighborhood by Bayesian rule. Suppose $i$'s continuation strategy is to play \textbf{revolt} repeatedly, then this is not ex-post efficient if $\#[Rebels](\theta)< k$. Suppose $i$'s continuation strategy is to play \textbf{stay} repeatedly, then this is not ex-post efficient if $\#[Rebels](\theta)\geq k$
\end{proof}

\bigskip
\noindent\textbf{proof for Theorem ~\ref{lemma_empty}}

This proof follows three useful claims, Claim ~\ref{lemma_I_subset_N}, Claim ~\ref{lemma1} and Claim ~\ref{lemma_connected}. First note that $I^t_i$ and $N^t_i$, $t\geq 1$ can be expressed as 
\begin{equation}
\label{eq_info_nb}
I^{t}_i = \bigcup_{k_0\in G_i\cap R^{t}}\bigcup_{k_1\in G_{k_0}\cap R^{t-1}}...\bigcup_{k_{t-1}\in G_{k_{t-2}}\cap R^{1}}G_{k_{t-1}}\cap R^0
\end{equation}
, while $H^t_i$ can be expressed as
\begin{equation}
\label{eq_nb}
N^t_i = \bigcup_{k_0\in G_i\cap R^{t-1}}\bigcup_{k_1\in G_{k_0}\cap R^{t-2}}...\bigcup_{k_{t-2}\in G_{k_{t-3}}\cap R^{0}}G_{k_{t-2}}
\end{equation}

\begin{claim}
\label{lemma_I_subset_N}
$I^t_i\subset N^t_i$ for $t\geq 1$
\end{claim}
\begin{proof}
$I^t_0\subset N^t_0$ by definition. Since $R^t\subset R^{t-1}$ for $t\geq 1$, $I^t_i\subset N^t_i$ for $t\geq 1$ by comparing Equation ~\ref{eq_info_nb} and Equation ~\ref{eq_nb}.
\end{proof}

\begin{claim}
\label{lemma1}
If the network is without cycle, then for each $t\geq 1$ block, we have $i\in R^t\Leftrightarrow i\in R^{t-1} \text{ and } \exists k_1,k_2\in R^{t-1}\cap \bar{G}_i$, where $k_1\neq k_2$.
\end{claim}
\begin{proof}
The proof is done by induction. We first show that the statement is true for $t=1$. 

\textbf{Base}: $i\in R^1\Leftrightarrow [i\in R^0] \wedge [\exists k_1,k_2\in (R^0\cap \bar{G}_i)]$. 

$\Rightarrow$: Since $i\in R^1$, then $i\in R^0$ and then $I^0_i\nsubseteq N^0_j$ for all $j\in \bar{G}_i$ by definition. Since $I^0_i=R^0\cap G_i$, then $\forall j\in \bar{G}_i [\exists k\in (R^0\cap \bar{G}_i) [k\notin N^0_j]]$. Since the $j\in \bar{G}_i$ is arbitrary,  we then have a pair of $k_1, k_2 \in (R^0\cap \bar{G}_i)$ such that $k_1\notin N^0_{k_2}$ and $k_2\notin N^0_{k_1}$.

$\Leftarrow$: Pick $k\in \{k_1,k_2\}\subseteq (R^0\cap \bar{G}_i)$, and pick an arbitrary $j\in \bar{G}_i\backslash \{k\}$. Note that $k\notin N^0_j$, otherwise there is a cycle from $i$ to $i$. Hence $[k\in (R^0\cap \bar{G}_i)] \wedge [k\notin N^0_j]$ and therefore $[k\in I^0_i] \wedge [k\notin N^0_j]$. Then we have $I^0_i\nsubseteq N^0_j$ for arbitrary $j\in \bar{G}_i$, and thus $i\in R^1$.

\textbf{Induction hypothesis}: the statement is true for $\{1,2,..,t\}$ where $t\geq 1$. 


If the hypothesis is true, then $i\in R^{t+1}\Leftrightarrow [i\in R^{t}] \wedge [\exists k_1,k_2\in (R^{t}\cap \bar{G}_i)]$


$\Rightarrow$: since $i\in R^{t+1}$, then $i\in R^t$ and $I^t_i\nsubseteq N^t_j$ for all $j\in \bar{G}_i$ by definition. Recall that $I^t_i$ can be expressed as Equation ~\ref{eq_info_nb} and $H^t_i$ can be expressed as Equation ~\ref{eq_nb}, then for every $l\in I^{t-1}_i$, we can find a path connecting $i$ to $l$ by the induction hypothesis. If $j\in \bar{G}_i$, then we can find a path connecting $j$ to $l$ by connecting $j$ to $i$, and then connecting $i$ to $l$. Thus, if $l\in I^{t-1}_i$ then $l\in N^t_J$, and hence $I^{t-1}_i\subseteq N^t_{j}$ for all $j\in \bar{G}_i$. Recall that $I^t_i = \bigcup_{k\in N_i\cap R^t}I^{t-1}_k$ and $i\in R^{t+1}$, then we must have $\forall j\in \bar{G}_i [\exists k\in (R^t\cap \bar{G}_i)[ I^{t-1}_k\nsubseteq N^t_j]]$, since $I^{t-1}_i\subseteq N^t_{j}$. Note that such $j\in \bar{G}_i$ is arbitrary,  we then have a pair of $k_1, k_2 \in (R^{t}\cap \bar{G}_i)$ such that $k_1\notin N^t_{k_2}$ and $k_2\notin N^t_{k_1}$.
\bigskip

$\Leftarrow$:
By the induction hypothesis, we have a chain $k_{1_0},...,k_{1_t},i,k_{2_t},...,k_{2_0}$ with $k_{1_0}\in R^0$,..., $k_{1_t}\in R^t$, $i\in R^t$, $k_{2_t}\in R^t$,...,$k_{1_0}\in R^0$, where $k_{1_t},k_{2_t}\in (R^{t}\cap \bar{G}_i)$, $k_{1_0}\in I^{t-1}_{k_{1_t}}$ and $k_{2_0}\in I^{t-1}_{k_{2_t}}$. Note that $k_{1_0}\notin N^t_j$ whenever $j\in \bar{G}_i$, otherwise there is a cycle from $i$ to $i$ since $\{i,k_{2_t},...,k_{2_0}\}\in N^t_j$, and hence $[k_{1_0}\in I^{t-1}_{k_{1_t}}] \wedge [k_{1_0}\notin N^t_j]$ for all $j\in \bar{G}_i$. Therefore we have $[I^{t-1}_{k_{1_t}}\in I^t_i] \wedge [I^{t-1}_{k_{1_t}}\notin N^t_j]$ for all $j\in \bar{G}_i$ since $k_{1_t},k_{2_t}\in (R^{t}\cap \bar{G}_i)$ and $[k_{1_0}\in I^{t-1}_{k_{1_t}}] \wedge [k_{1_0}\notin N^t_j]$ for all $j\in \bar{G}_i$. Then we have $I^t_i=\bigcup_{k\in N_i\cap R^{t}}I^{t-1}_k\nsubseteq N^t_j$ for arbitrary $j\in \bar{G}_i$, and thus $i\in R^{t+1}$.



We can then conclude that the statement is true by induction.




\end{proof}



\begin{claim}
\label{lemma_connected}
If the network  is without cycle and if the state has strong connectedness, then if there is a pair of $R^{t}$ nodes, then there exists a $R^{t}$-path connecting them.
\end{claim}
\begin{proof}
The proof is done by induction and by Claim ~\ref{lemma1}. Since the state has strong connectedness, we have a $R^0$-path connecting each pair of $R^0$ nodes. Since all pairs of $R^0$ nodes are connected by a $R^0$-path, then for all pairs of $R^1$ nodes must be in some of such paths by Claim ~\ref{lemma1}, and then connected by a $R^0$-path. But then all the $R^0$-nodes in such path are all $R^1$ nodes by Claim ~\ref{lemma1} again and by $R^t\subseteq R^{t-1}$ for $t\geq 1$ by definition. Thus, for all pairs of $R^1$ nodes has a $R^1$-path connecting them. The similar argument holds for $t> 1$, we then get the result.

\end{proof}
I begin to prove Theorem ~\ref{lemma_empty}. I first claim that if $R^t\neq \emptyset$ and if $R^{t+1}= \emptyset$, then $R^0\subset I^t_i$ whenever $i\in R^t$. Then I claim that if $R^t\neq \emptyset$ then $\# R^{t+1}<\# R^t$. Finally, I iterate $R^t$ with $t\geq 0$ to get the conclusion.

If $R^t\neq \emptyset$ but $R^{t+1}= \emptyset$, I claim that $R^0\subset I^{t}_i$ for all $i\in R^t$. The proof is by contradiction. If $R^0\not\subset I^{t}_i$, there is a $j\in R^0$ but $j\notin I^t_i$. Since $I^t_i$ can be expressed as Equation ~\ref{eq_info_nb}, there is no such a path $\{i,k_0,k_1,...,k_{t-1},j\}$, where $k_0\in G_i\cap R^{t},k_1\in G_{k_0}\cap R^{t-1},...,k_{t-1}\in N_{k_{t-2}}\cap R^{1}$. Since $R^{t+1}=\emptyset$ and therefore $R^{t^{'}}=\emptyset$ if $t^{'}\geq t+1$, and hence there is no such a path containing a node in $R^{t^{'}}=\emptyset$, where $t^{'}\geq t+1$ connecting $i$ to $j$. But $i\in R^t$ and $i,j\in R^0$, if there is no such a path, then it violate either Claim ~\ref{lemma_connected} or Claim ~\ref{lemma1}. Contradiction.

Next I claim that if $R^t\neq \emptyset$ then $\# R^{t+1}<\# R^t$. The proof is the followings. Given a node $i$ in $R^t$, let $j\in R^t$ (could be $i$ itself) be the node connected with $i$ with the maximum shortest $R^t$ path. This $j$ can be found since $R^t\neq \emptyset$ and the network is finite. Then there is no $R^t$ node in $j$'s neighborhood other than the nodes in this path. Since the network is without cycle, there is at most one $R^t$ node in $j$'s neighborhood. But then $j\notin R^{t+1}$ since it violate Claim ~\ref{lemma1}.

Starting from $R^0\neq \emptyset$ and iterating $R^t$ with $t\geq 0$, if $R^t\neq \emptyset$ but $R^{t+1}= \emptyset$, then there is some $i$ with $R^0\subset I^t_i$ as the above paragraph shows; if $R^t\neq \emptyset$ and $R^{t+1}\neq \emptyset$, then we starting from $R^{t+1}$ and iterating $R^{t+1}$ with $t\geq t+1$. Since $\#R^{t+1}<\#R^t$ as the above paragraph shows, there is a time $t^{*}$ with $R^{t^{*}}=\emptyset$, then we get the conclusion.


\bigskip




\noindent\textbf{proof for Lemma ~\ref{lemma_at_most_two_nodes}}

\begin{proof}
Denote $(i,j)$-path as the set of paths from $i$ to $j$. The proof is by contradiction. Suppose there are three or more $R^t$-nodes in $C^t$, then pick any three nodes of them, and denote them as $i_1,i_2,i_3$. Let's say $i_2$ is in a $(i_1,i_3)$-path by strong connectedness, and therefore $i_2\in TR_{i_1i_2}$ and $i_3\in TR_{i_2i_3}$. First we show that $i_1\in G_{i_2}$ (or $i_3\in G_{i_2}$). Suppose $i_1\notin N_{i_2}$, since $i_1,i_2\in R^t$, then the $(i_1,i_2)$-path is a $R^t$-path by Claim ~\ref{lemma1}. Let this $(i_1i_2)$-path be $\{i_1,j_1,...,j_n,i_2\}$. Since $i_1,j_1,...,j_n,i_2\in R^t$, we then have $I^{t-1}_{i_1}\nsubseteq N^{t-1}_{j_1},...,I^{t-1}_{j_n}\nsubseteq N^{t-1}_{i_2}$ and $I^{t-1}_{j_1}\nsubseteq N^{t-1}_{i_1},...,I^{t-1}_{i_2}\nsubseteq N^{t-1}_{j_n}$. Since $I^{t-1}_{i_1}\subseteq N^{t-1}_{i_1},...,I^{t-1}_{i_2}\subseteq N^{t-1}_{i_2}$ by Claim ~\ref{lemma_I_subset_N}, we further have $\exists k_1\in R^0[k_1\in N^{t-1}_{j_1}\backslash I^{t-1}_{i_1}]$,...,$\exists k_n\in R^0[k_n\in N^{t-1}_{j_n}\backslash I^{t-1}_{i_2}]$. Since the state has strong connectedness, there is a $R^0$ path connecting $k_1,...,k_n$ by Claim ~\ref{lemma_connected}. But then we have already found $k_1,k_2$ such that $k_1\in N^{t-1}_{j_1}\backslash I^{t-1}_{i_1}$ and $k_2\in \bar{G}_{k_1}$. It is a contradiction that $i_1\in C$.

Now, $i_1,i_2,i_3$ will form a $R^t$-path as $\{i_1,i_2,i_3\}$. With the same argument as the above, we then have $\exists k_1\in R^0[k_1\in N^{t-1}_{i_2}\backslash I^{t-1}_{i_1}]$ and $\exists k_2\in R^0[k_2\in N^{t-1}_{i_3}\backslash I^{t-1}_{i_2}]$, and thus $i_1$ is not in $C$.
\end{proof}


\noindent\textbf{proof for Lemma ~\ref{lemma_no_node_outside}}
\begin{proof}
The proof is done by contradiction. Since $i\in R^t$, there is a $j\in (R^{t-1}\cap \bar{G}_i)$ by Lemma ~\ref{lemma1}. Note that $N^{t-1}_j\subseteq \bigcup_{k\in N^{t-1}_i}N_k$ since $N^{t-1}_j =\bigcup_{k\in I^{t-2}_j}N_k$, and $I^{t-2}_j\subseteq I^{t-1}_i\subseteq N^{t-1}_i$. If there is another node outside $\bigcup_{k\in N^{t-1}_i}N_k$ in $TR_{ij}$, then there must be another node such that there is a path connected to some nodes in $N^{t-1}_j$ since the network is connected. It is a contradiction that $i\in C$.

\end{proof}

\subsection{Equilibrium}
\label{appx_network_equilibrium}
\subsubsection{Out-off-path belief}

If Rebel $i$ detects a deviation at $m$ period, he forms the belief as
\begin{equation}
\beta_{i}(\{\theta:\theta\in \times_{j\in G_i}\{\theta_j\}\times\{Inert\}^{n-\#G_i}\}|h^{m^{'}}_{G_i})=1 \text{ , } m^{'}\geq m
\end{equation}



\subsubsection{Equilibrium Path: Notations}


\begin{itemize}
\item $\langle \rangle$ is a finite sequence.
\item $|\langle \rangle|$ is the length of finite sequence $\langle \rangle$.
\item $\langle \rangle_r$ is the set of finite sequences in which the action \textbf{r} occurs once and only once.
\item $PF(\langle \rangle,m)$ is the $m$-periods prefix of a finite sequence $\langle \rangle$.
\item If $\langle \rangle\in \langle \rangle_r$, then let $||\langle \rangle||=\arg\min\{m\in\{1,...,|\langle \rangle|\}|PF(\langle \rangle,m)\in \langle \rangle_r\}\}$ 
\item $(i,j)$-path is the set of paths from $i$ to $j$.
\item $(RP)^t$ is the period in the end of $RP^t$.

\end{itemize}

\subsubsection{Equilibrium Path: reporting period}

\paragraph{reporting period: notations}

\begin{itemize}
\item $m$ is a period in reporting period in $t$ block.
\item $| RP^t |$ is the total periods in reporting period in $t$-block
\item $O^{m,t}_i$ is the set of $i$'s neighbors $j$s who has played a sequence $M$ such that $M=PF(\langle I^{t-1}_j \rangle,m)$ and $M \in \langle \rangle_r$ at period $m$. 
\item $I^{m,t}_i\equiv (\bigcup_{k\in O^{m,t}_i} I^{t-1}_k)\cup I^{t-1}_i$ is the updated relevant information gathered by $i$ at period $m$. Note that $I^{0,t}_i=I^{t-1}_i$ and $I^{| RP^t|,t }_i=I^{t}_i$.
\item $N^{m,t}_i\equiv (\bigcup_{k\in O^{m,t}_i} N^{t-1}_k)\cup N^{t-1}_i$
is the updated neighborhood which contains $I^{m,t}_i$

\item Let 
\[Ex_{I^{m,t}_i}\equiv \{l\notin N^{m,t}_i|\exists l^{'}\in I^{m,t}_i\text{ such that there exists a $(l,l^{'})$-path}\}\]
be all the possible Rebel nodes outside of $N^{m,t}_i$ given $I^{m,t}_i$
\item Let
\[TR_{I^{m,t}_ij}\equiv TR_{ij}\cap (Ex_{I^{m,t}_i}\cup I^{m,t}_i)\]
be all the possible Rebel nodes in the $TR_{ij}$ given $I^{m,t}_i$. 
\end{itemize}
\paragraph{reporting period: automata}
\subparagraph{$i\notin R^{t}$}




\begin{itemize}
\item \textbf{WHILE LOOP}
\begin{itemize}
\item At $m\geq 0$, if $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i< k$, report $\langle \textbf{stay} \rangle$ and then play \textbf{stay} forever.
\item Otherwise, \textbf{runs POST-CHECK }
\end{itemize}
\end{itemize}

\subparagraph{$i\in R^{t}$}

\begin{itemize}

\item \textbf{WHILE LOOP}
\begin{itemize}
\item At $m\geq 0$, if $\# Ex_{I^{m,t}_i}\cup I^{m,t}_i< k$, report $\langle \textbf{stay} \rangle$ and then play \textbf{stay} forever.
\item Otherwise, \textbf{runs MAIN }
\end{itemize}


\item \textbf{MAIN}

At $m\geq 0$, 

\begin{enumerate}
\item At $m=0$ and if $\# I^{t-1}_i=\# I^{0,t}_i= k-1$, then 
\textbf{runs POST-CHECK }


\item At $m=0$ and if $i\in R^t$ and
\[\nexists j\in R^{t-1}\cap\bar{G}_i \text{ such that }\exists l_1,l_2\in TR_{ij}[[l_1\in N^{t-1}_j\backslash I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_1}]]]\]
, then runs \textbf{CHECK.$0$}. Otherwise, recall \textbf{MAIN}
\item At $0\leq m \leq |RP^t|-||\langle I^{t-1}_i \rangle||$, play
\[\textbf{stay}\]
\item At $m = |RP^t|-||\langle I^{t-1}_i \rangle||+1$, then
\begin{enumerate}
\item if $O^{m,t}_i= \emptyset$ 
, then report
\[\langle I^{t-1}_i \rangle\]
\item if $O^{m,t}_i\neq \emptyset$, then \textbf{runs CHECK.k}

\end{enumerate}

\end{enumerate}





\item \textbf{CHECK.$0$}

At $m=0$, if $i\in C^t$, i.e. if $i\in R^t$ and
\[\nexists j\in R^{t-1}\cap \bar{G}_i \text{ such that }[\exists l_1,l_2\in TR_{ij}[[l_1\in N^{t-1}_j\setminus I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_1}]]]\]
, then
\begin{enumerate}
\item If $\#C^t=1$
, then 
\textbf{runs POST-CHECK }

\item If $\#C^t=2$, then denote $i_1,i_2\in C$ such that $I^{t-2}_{i_1}<I^{t-2}_{i_2}$, and then
\begin{itemize}
\item if $i=i_1$, then 
\textbf{runs POST-CHECK }
\item if $i=i_2$, then report
\[\langle I^{t-1}_i \rangle\]

\end{itemize}
\end{enumerate}




\item \textbf{CHECK.$m$}

 At $m>0$, if $O^{m,t}_i\neq \emptyset$, then there are two cases, 
\begin{enumerate}
\item Case 1: If $i\in R^t$ and 
\[\exists j\in  O^m_i \text{ such that }\exists l_1,l_2\in TR_{I^{m,t}_ij}[[l_1\in I^{t-1}_j\backslash I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_1}]]]\]
, then report 
\[\langle I^{t-1}_i \rangle\]
\item Case 2: If $i\in R^t$ and 
\[\not\exists j\in  O^m_i \text{ such that }\exists l_1,l_2\in TR_{I^{m,t}_ij}[[l_1\in I^{t-1}_j\backslash I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_1}]]]\]

\begin{enumerate}
\item Case 2.1: If $i\in R^t$ and 
\[\not\exists j\in R^{t-1}\cap (G_i\backslash  O^{m,t}_i) \text{ such that }[\exists l_1,l_2\in TR_{I^{m,t}_ij}[[l_1\in N^{t-1}_j\backslash I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_2}]]]\]
\[\textbf{Note: this case is the case when $i\in C$, thus recall Check.0}\]

\item Case 2.2: If $i\in R^t$ and 
\[\exists j\in R^{t-1}\cap (G_i\backslash  O^{m,t}_i) \text{ such that }[\exists l_1,l_2\in TR_{I^{m,t}_ij}[[l_1\in N^{t-1}_j\backslash I^{t-1}_i] \wedge [l_2\in \bar{G}_{l_2}]]]\]

\begin{itemize}
\item if $\# I^{m,t}_i= k-1$
, then 
\textbf{runs POST-CHECK }

\item if $\# I^{m,t}_i< k-1$
, then report 
\[\langle I^{t-1}_i \rangle\]
\end{itemize}





\end{enumerate}

\end{enumerate}





\item \textbf{CHECK.k}

At $m\geq 1$, 
\begin{enumerate}


\item $O^{m,t}_i\neq \emptyset$, and
 \[\# I^{m,t}_i\geq k\]
, then 
\textbf{runs POST-CHECK }

\item $O^{m,t}_i\neq \emptyset$, and 
\[ \#I^{m,t}_i< k\]
, then \textbf{runs CHECK.$m$}
\end{enumerate}


\item \textbf{POST-CHECK}

\begin{enumerate}


\item At $m=|RP^t|$, then
\begin{enumerate}
\item If $i\in R^t$ and if $\# I^{m,t}_i\geq k-1$, then play
\textbf{revolt}

\item if $i\notin R^t$, then play
\textbf{stay}


\end{enumerate}
\end{enumerate}


\end{itemize}



\subsubsection{Equilibrium path: coordination period}
\paragraph{coordination period: notations}
\begin{itemize}
\item $m$ is a sub-block in the coordination period.
\item Let 
\[Ex_{I^{t}_i}\equiv \{l\notin I^{t}_i|\exists l^{'}\in I^{t}_i\setminus I^{t-1}\text{ such that there exists a $(l,l^{'})$-path}\}\]
be all the possible Rebel nodes outside of $N^{t}_i$ given $I^{t}_i$.

\item Let
\[TR_{I^{t}_ij}\equiv TR_{ij}\cap (Ex_{I^{t}_i}\cup I^{t}_i)\]
be the set of possible Rebel nodes in the $TR_{ij}$ given $I^{t}_i$. 

\end{itemize}




\paragraph{coordination period: automata}


\begin{itemize}





\item \textbf{1st Division} 

In 1st division, for $t=0$ block,

\begin{itemize}



\item If $\# Ex_{I^{t}_i}\cup I^{t}_i<k$, then play \textbf{stay} forever.

\item If $\# Ex_{I^{t}_i}\cup I^{t}_i \geq k$, and if $i\not\in R^1$, then play
\[\langle \textbf{stay} \rangle\]

\item If $\# Ex_{I^{t}_i}\cup I^{t}_i \geq k$, and if $i\in R^1$, then play
\[\langle x_i \rangle\]


\end{itemize}

In 1st division, for $t>0$ block and for $1\leq m \leq n$ sub-block,
\begin{itemize}

\item If $i$ has played $\langle 1 \rangle$, then play 
\[\langle x_i \rangle\]

\item If $\# Ex_{I^{t}_i}\cup I^{t}_i<k$, then play \textbf{stay} forever.

\item If $\# Ex_{I^{t}_i}\cup I^{t}_i\geq k$, and there are some $j\in \bar{G}_i$ have played $\langle \textbf{stay} \rangle $, then play
\textbf{stay} forever.
\item If $\# Ex_{I^{t}_i}\cup I^{t}_i \geq k$, and there is no $j\in \bar{G}_i$ has played $\langle \textbf{stay} \rangle $, then play
\[\langle x_i \rangle\]

\end{itemize}




\item \textbf{2nd Division} 

In $t=0$ block
\begin{itemize}
\item If $i\notin R^1$, play \[\langle \textbf{stay} \rangle \].
\item If $i\in R^1$, and if $\#I^0_i\geq k$, play \[\langle \textbf{stay} \rangle \].
\item If $i\in R^1$, if $\#I^0_i< k$, if $\# Ex_{I^{t}_i}\cup I^{t}_i\geq k$ and if some $j\in \bar{G}_i$ have played play $\mathbf{1}_j$ in the 1st division, then play \[\langle \textbf{stay} \rangle \].
\item If $i\in R^1$, if $\#I^0_i< k$, if $\# Ex_{I^{t}_i}\cup I^{t}_i\geq k$ and if no $j\in \bar{G}_i$ has played play $\mathbf{1}_j$ in the 1st division, then play \textbf{stay} forever.

\end{itemize}


In $t>0$ block, if there is no $j\in G_i$ such that $j$ has played $\langle \textbf{stay} \rangle$ in the \textbf{1st Division} , then run the following automata. Otherwise, play \textbf{stay} forever.

\begin{itemize}
\item $i\notin R^t $
\begin{itemize}
\item In the $1$-sub-block: play
\[\langle \textbf{stay} \rangle \]


\item In the $2\leq m\leq t+1$ sub-blocks: 

\begin{enumerate}

\item If $i\in R^{t^{'}}$ for some $t^{'}\geq 0$ and if there is a $j\in R^{t^{'}+1}\cap \bar{G}_i$ has played 
\begin{enumerate}
\item $\langle \textbf{stay} \rangle $ in $m=1$ sub-block
\item or $\langle \mathbf{1}_j \rangle$ in $m\geq 2$ sub-blocks
\end{enumerate}
, then play 
\[\langle x_i \rangle\] in $m+1$ sub-block.

\item Otherwise, play
\[\langle \textbf{stay} \rangle\] in current sub-block
\end{enumerate}

\end{itemize}

\item $i\in R^t$

\begin{itemize}
\item In the $1$-sub-block:
\begin{enumerate}
\item If $i$ has played $\langle 1 \rangle$, then play
\[\langle \textbf{stay} \rangle \]

\item If $i$ has not played $\langle 1 \rangle$ and if there is a $j\in \bar{G}_i$ has played $\langle 1 \rangle$, then play
\[\langle \textbf{stay} \rangle \]

\item If $i$ has not played $\langle 1 \rangle$ and if there is no $j\in \bar{G}_i$ has played $\langle 1 \rangle$, then
\begin{itemize}
\item If $\# I^{|RP^t|,t}_i\geq k$, then play
\[\langle \textbf{stay} \rangle \]
\item If $\# I^{|RP^t|,t}_i< k$, then play
\[\langle \mathbf{1}_i  \rangle \]
\end{itemize}

\end{enumerate}

\item In the $m\geq 2$-sub-block: 

\begin{enumerate}

\item If $i\in R^{t^{'}}$ for some $t^{'}\geq 0$ and if there is a $j\in R^{t^{'}}\cap \bar{G}_i$ has played 
\begin{enumerate}
\item $\langle \textbf{stay} \rangle$ in $m=1$ sub-block, or
\item $\langle \mathbf{1}_j \rangle$ in $m\geq 2$ sub-blocks
\end{enumerate}
, then play 
\[\langle x_i \rangle\] in $m+1$ sub-block.
\item Otherwise, play
\[\langle \textbf{stay} \rangle\] in current sub-block.
\end{enumerate}

\end{itemize}

\end{itemize}



\item \textbf{3rd Division} 

\begin{enumerate}
\item \textbf{INITIATING} 

If $i$ has observed $j\in \bar{G}_i$ has played
\begin{enumerate}
\item $\langle \textbf{stay} \rangle$ in $1$-sub-block in \textbf{2nd Division}  or
\item $\langle \mathbf{1}_j \rangle$ in $m\geq 2$ sub-blocks \textbf{2nd Division}  or
\item \textbf{s} in the \textbf{3rd Division} 
\end{enumerate}
, then play \textbf{revolt} forever

\item \textbf{NOT INITIATING} 

Otherwise, play 
\textbf{stay} 
in current period.
\end{enumerate}
\end{itemize}





\subsubsection{Proof for Theorem ~\ref{thm_main_result}}


The proof is organized as follows. In Claim ~\ref{claim_either_success_or_fail} and Lemma ~\ref{lemma_in_the_path}, I show that a Rebel will learn $\#[Rebels](\theta)\geq k$ or $\#[Rebels](\theta)< k$ in the equilibrium path. Lemma ~\ref{lemma_in_the_path} also show that the equilibrium path is ex-post efficient. Since that, there is a $T$ such that a Rebel's static payoff after $T$ is $1$ if $\#[Rebels](\theta)\geq k$; is $0$ if $\#[Rebels](\theta)\geq k$. Such payoff is the maximum static payoff contingent on $\theta$ after time $T$. In Claim ~\ref{claim_detection_reporting_period}, I show that if a Rebel makes detectable deviation, then there is a positive probability event $E$ (by the full support assumption) contingent on this deviation such that his expected continuation static payoff is strictly lower than that in equilibrium path after $T$. Finally, in Claim ~\ref{claim_deviation_higher_reporting}, Claim ~\ref{claim_can_not_pretend_almost_success}, Claim ~\ref{claim_must_report_1}, and Claim ~\ref{claim_report_with_no_message_coordination_period}, I show that if a Rebel makes undetectable deviation, then there is a positive probability event $E$ (by the full support assumption) contingent on this deviation such that his expected continuation static payoff is also strictly lower than that in the equilibrium path after $T$. Since the static payoff after $T$ is maximum for all $\theta$ in equilibrium path, there is a $\delta$ such that a Rebel will not deviate. I then conclude this theorem.

To simplify the notations, if $P(\theta)$ is a property of $\theta$, then I abuse the notations by letting $\beta^{\pi,\tau^*}_{G_i}(P(\theta)|h^{m}_{G_i})\equiv \sum_{\theta:P(\theta)}\beta^{\pi,\tau^*}_{G_i}(\theta|h^{m}_{G_i})$. I also say ``$i$ knows $P(\theta)$'' to mean $\beta^{\pi,\tau^*}_{G_i}(P(\theta)|h^{m}_{G_i})=1$. 




\begin{claim}
\label{claim_either_success_or_fail}
Assume that players follow the equilibrium path. Then if $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i\geq k$, where $m$ is a period in $RP^t$, then if $i$ reports $\langle 1 \rangle$, then Rebels coordinate to \textbf{revolt} after $t$-block, or $\# R^0<k$.
\end{claim}
\begin{proof}
By directly checking the equilibrium path, we have
\begin{enumerate}
\item if $\# I^{|RP^t|,t}_i\geq k$, then the coordination can be initiated by such $i$.
\item if $\# I^{|RP^t|,t}_i= k-1$, and if there is one more node who reported $\langle 1 \rangle$, then the coordination can be initiated by $i$.
\item if $\# I^{|RP^t|,t}_i= k-1$, and if there are no nodes who reported in current reporting period, then $\# I^{|RP^t|,t}_i=\# I^{t}_i= k-1$. We now check the conditions guiding $i$ to \textbf{POST-CHECK}.
\begin{itemize}
\item If $i$ is coming from the conditions in \textbf{MAIN}, it means that there are no further Rebels outside $I^{t-1}_i$, thus outside $\bigcup_{k\in I^{t-1}_i}G_k$.
\item If $i$ is coming from the conditions in \textbf{CHECK.0}, it means that there are no further Rebels outside $\bigcup_{k\in I^{t-1}_i}G_k\cap R^0$, and thus outside $\bigcup_{k\in I^{t-1}_i}G_k$. 
\item If $i$ is coming from the conditions in \textbf{CHECK.m}, it means that there are no further Rebels outside $\bigcup_{k\in I^{t-1}_i}G_k\cap R^0$, and thus outside $\bigcup_{k\in I^{t-1}_i}G_k$. 
\end{itemize}
Since $I^t_i=\bigcup_{k\in I^{t-1}_i}G_k\cap R^0 \subset \bigcup_{k\in I^{t-1}_i}G_k$ and $\#I^t_i<k$, and hence $\# R^0<k$.

\end{enumerate}


\end{proof}




\noindent \textbf{proof for Lemma ~\ref{lemma_in_the_path}}
\begin{proof}
We want to show that all Rebels play \textbf{revolt} eventually when $\theta$ satisfies $\#[Rebels](\theta)\geq k$; all Rebels play \textbf{stay} eventually when $\theta$ satisfies $\#[Rebels](\theta)< k$.
\begin{enumerate}
\item If all Rebels only play $\langle I^{t-1} \rangle$ or $\langle \textbf{stay} \rangle$ in the reporting period for all $t\geq 1$ block, then, in the equilibrium path, those nodes played $\langle I^{t-1} \rangle$ are $R^t$-node, and those nodes played $\langle \textbf{stay} \rangle$ are non-$R^t$ nodes. 

If there are some Rebels play $\langle \textbf{stay} \rangle$ in $CD^t_{1,1}$, then all the Rebels play \textbf{stay} eventually; If $R^t$ Rebels play $\langle \textbf{stay} \rangle$ in $CD^t_{1,2}$, then all the Rebels will play \textbf{revolt} after third division in coordination period in this block. Otherwise, all the Rebels go to the next reporting period.

By Theorem ~\ref{lemma_empty}, there is a $t^{*}$ such that there is a $R^{t^{*}}$ node knows $\theta$, and therefore he knows if $\theta$ satisfying $\#[Rebels](\theta)\geq k$ or $\#[Rebels](\theta)< k$. In the equilibrium path, such node that plays $\langle \textbf{stay} \rangle$ is either in $CD^{t^{*}}_{1,1}$ or in $CD^{t^{*}}_{1,2}$. Thus, the equilibrium path is APEX.

\item If there are some Rebels play $\langle 1 \rangle$ in reporting period for a $t\geq 1$ block, then by Claim ~\ref{claim_either_success_or_fail}, such nodes will knows if $\theta$ satisfying $\#[Rebels](\theta)\geq k$ or $\#[Rebels](\theta)< k$ after reporting period in this $t$-block. Then $\langle \textbf{stay} \rangle$ is either played in the first sub-block in first division or played in the first sub-block in second division in coordination period. Thus, the equilibrium path is APEX.

 
\end{enumerate}

\end{proof}



Next, I prepare the claims to show that a Rebel will not deviate. I start with Claim ~\ref{claim_detection_reporting_period} in which the deviation is detectable.


\begin{claim} 
\label{claim_detection_reporting_period}
Assume that player $i$ follows equilibrium path before $m$ period. Denote $D$ be the set of Rebels who detect $i$'s deviation at $m$ period. Then if $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i\geq k$, then if $\# I^{m,t}_i<k$ and if $D\neq \emptyset$, there is a $\delta$ such that $i$ will not deviate.
\end{claim}
\begin{proof}

Denote $D$ be the set of neighbors who detect $i$'s deviation. Let the events be
\begin{eqnarray*}
E_1 	&= &\{\theta: \#[Rebels](\theta)< k\}\\
E_2 	&= &\{\theta: k\leq \#[Rebels](\theta)<k+\# D\}\\
E_3 	&= &\{\theta: \#[Rebels](\theta)\geq k+\# D\}
\end{eqnarray*}

In the equilibrium path, there are periods $t^{s}$ ($t^{f}$) such that, if $\theta$ satisfying $\#[\text{Rebels}](\theta)\geq k$ ( $\#[\text{Rebels}](\theta)< k$) then Rebels play \textbf{revolt} (\textbf{stay}) forever. If $i$ follows the equilibrium path, the expected static payoff after $\max\{t^s,t^f\}$\footnote{There is $t^{s}$ or $t^{f}$ for each $\theta$. The maximum is among those possible $\theta$.} is
 \[\beta_{i}(E_2|h^{m}_{N_i})+\beta_{i}(E_3|h^{m}_{N_i})\]

If $i$ deviate, the expected static payoff after $\max\{t^s,t^f\}$ is
 \[\beta_{i}(E_3|h^{m}_{N_i})\]
 
Therefore there is a loss in expected static payoff of
\[\beta_{i}(E_2|h^{m}_{N_i})\]

Thus, there is a loss in expected continuation payoff contingent on $E_2$ by
\[\delta^{\max\{t^s,t^f\}}\frac{\beta_{i}(E_2|h^{m}_{N_i})}{1-\delta}\]

Note that $\beta_{i}(E_2|h^{m}_{N_i})>0$, since $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i\geq k$ and therefore $\beta_{i}(\#[Rebels](\theta)\geq k|h^{m}_{N_i})>0$ by full support assumption.
\end{proof}


Next, I prepare the claims to show that a Rebel will not deviate if such deviation is undetectable.

\begin{claim} 
\label{claim_deviation_higher_reporting}
Assume that player $i$ follows equilibrium path before $m$ period. Then if $\# Ex_{I^{m,t}_i}\cup I^{m,t}_i \geq k$ and $m$ is a period in $RP^t$, then if $\# I^{m,t}_i<k$,  there is a $\delta$ such that $i$ will not deviate by reporting $\bar{I}^{t-1}_i\neq I^{t-1}_i$ if such deviation is not detected by $i$'s neighbor.
\end{claim}

\begin{proof}
Assume $\bar{I}^{t-1}_i\neq I^{t-1}_i$. Since a detection of deviation has not occur, it must be the case that there is a non-empty set $F=\{j\in \bar{I}^{t-1}_i:\theta_j=Inerts\}$\footnote{Otherwise, there is a detection of deviation. Recall the definition in information hierarchy: $I^{-1}_i\subset I^{0}_i\subset...\subset I^{t-1}_i$ for all $i\in R^0$}. 


Let the set 
\[E_1=\{\bar{\theta}: \bar{\theta}_j=Rebel \text{ if } j\in F \text { and }\bar{\theta}_j=\theta_j \text{ if } j\notin F\}\]
be the set of pseudo events by changing $\theta_j$ where $j\in F$. And let
\[E_2=\{\theta: \theta_j=Inert \text{ if }j\in F \text { and }\bar{\theta}_j=\theta_j \text{ if } j\notin F\}\]
be the set of true event.

Then consider the event
\begin{eqnarray*}
E 	&= &\{\bar{\theta}\in E_1: \#[Rebels](\bar{\theta})\geq k\}\\
 	&= &\{\theta\in E_2: \#[Rebels](\theta)\geq k-\#F\}
\end{eqnarray*}

Partition $E$ as sub events
\begin{eqnarray*}
E_3 	&= &\{\theta\in E_2: \#[Rebels](\theta)\geq k\}\\
E_4 	&= &\{\theta\in E_2: k>\#[Rebels](\theta)\geq k-\#F\}
\end{eqnarray*}

By Lemma ~\ref{lemma_empty} and by following the strategies in equilibrium path (since $i$ has not been detected), there is a block $\bar{t}^{s}$ with respect to $\bar{\theta}$ such that if $\bar{\theta}\in E$ then there some $R^{\bar{t}^s}$ Rebel $j$s, says $J$, will initiate the coordination, and then Rebels play \textbf{revolt} forever after $\bar{t}^s$-block. Note that such $j$ is with $\# {I}^{\bar{t}^{s}}_i \geq k$ by checking the equilibrium path.

We have several cases:
\begin{enumerate}
\item Case 1: If $i\in J$, his own initiation will only depends on $\# I^{\bar{t}^s}_i$ by Claim ~\ref{claim_can_not_pretend_almost_success} and Claim ~\ref{claim_must_report_1}, which is the same as he has reported $\langle {I}^{t-1}_i\rangle$. He is strictly better off by not deviating since playing $\langle\bar{I}^{t-1}_i\rangle$ is more costly than $\langle\bar{I}^{t-1}_i\rangle$ (since $X_{\bar{I}^{t-1}_i}>X_{I^{t-1}_i}$).

\item Case 2: If there is another $j$ such that $\bar{I}^{t-1}_i\not\subset I^{\bar{t}^{s}}_j$, then since such $j$'s initiation of coordination dependent on his own information $I^{\bar{t}^{s}}_j$ by Claim ~\ref{claim_can_not_pretend_almost_success} and Claim ~\ref{claim_must_report_1}, and $i$'s deviation did not change $j$'s information. It is strictly better by not deviating since playing $\langle\bar{I}^{t-1}_i\rangle$ is more costly than $\langle\bar{I}^{t-1}_i\rangle$ (since $X_{\bar{I}^{t-1}_i}>X_{I^{t-1}_i}$).

\item Case 3: Suppose there is another $j$ such that $\bar{I}^{t-1}_i\subset {I}^{\bar{t}^{s}}_j$ and $\# I^{\bar{t}^s}_i\geq k$, then such $j$ will initiate  the coordination to \textbf{revolt}. If $i$ did not follow $j$'s initiation of coordination, then there is a detection of deviation by checking the equilibrium path. $i$ will not deviate as Claim ~\ref{claim_detection_reporting_period} shows. If $i$ follows, and $\#I^{\bar{t}^s}_i\geq s$, we are in the Case 1. If $i$ follows, but $\#I^{\bar{t}^s}_i< s$, then $i$'s expected static payoff after $\bar{t}^{s}$ is at most
\[
{\max\{\beta_{i}(E_3|h^{m}_{N_i})\times 1+\beta_{i}(E_4|h^{m}_{N_i})\times (-1), 0\}}
\]

However, if $i$ follows the equilibrium path, there is are $t^s$, $t^f$ such that the expected static payoff after $\max\{t^s,t^f\}$ is
\[\max\{\beta_{i}(E_3|h^{m^{'}}_{N_i}),0\}\]

Thus, there is a loss in expected continuation payoff contingent on $E$ by
\[\delta^{\max\{t^s,t^f\}}\frac{\min\{\beta_{i}(E_3|h^{m}_{G_i}),\beta_{i}(E_4|h^{m}_{G_i})\}}{1-\delta}\]
\end{enumerate}

Note that $\beta_{i}(E_3|h^{m}_{N_i})>0$ and $\beta_{i}(E_3|h^{m}_{N_i})>0$, since $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i\geq k$ and $\# I^{m,t}_i<k$, and therefore $1>\beta_{i}(\#[Rebels](\theta)\geq k|h^{m}_{N_i})>0$ by full support assumption.
\end{proof}



\begin{claim} 
\label{claim_can_not_pretend_almost_success}
Assume that player $i$ follows equilibrium path before $m$ period. Then if $\#Ex_{I^{m,t}_i}\cup I^{m,t}_i\geq k$ and $m$ is a period in $RP^t$, then if $\#I^{m,t}_i\leq k-1$, $i$ will not play $\langle 1 \rangle$ given that $i\notin C^t$ or $i$ does not satisfy the conditions to play $\langle 1 \rangle$.
\end{claim}


\begin{proof}


Let
\[E^{'}=\{\theta:\#I^{RP^t,t}_i\leq k-1\}\]
. Note that such event is not empty by checking the timing where $i$ deviated:
\begin{enumerate}
\item If $i$ has a neighbor $j\in C^t$, then $j\not\in O^{RP^t,t}_i$, and therefore we can construct $E^{'}$ by assuming that all other neighbors (other than $i,j$ and other than $l\in O^{m,t}_i$) are non-$R^t$.
\item If \[\exists j\in R^{t-1}\cap \bar{G}_i \text{ such that } \exists k_1,k_2\in TR_{ij}[[k_1\in N^{t-1}_j\backslash I^{t-1}_i] \wedge [k_2\in \bar{G}_{k_2}]]\], then just let $E^{'}=\{\theta: N^t_i\cap R^0\leq k-1\}=\{\theta: I^t_i\leq k-1\}$\footnote{note that $I^t_i$=$I^{RP^t,t}_i$}.
\end{enumerate}

Next, let 
\begin{eqnarray*}
E_1&=&\{\theta: \#[Reble](\theta)<k\}\cap E^{'}\\
E_2&=&\{\theta: \#[Reble](\theta)\geq k\}\cap E^{'}\\
\end{eqnarray*}

Note that $E_1$ and $E_2$ are not empty. According to the equilibrium path, if $i$ did not follow the conditions to play $\langle 1 \rangle$, it must be the case that there are some nodes outside $I^t_i$ but there is a path consisting of Rebels to connect them. By strong connectedness, $E_1$ and $E_2$ are not empty.

Since $i$ deviate to play $\langle 1 \rangle$, his behavior after $CD^t_{1,1}$ will decide the following three cases:
\begin{enumerate}
\item If $i$ play $\langle \textbf{stay} \rangle$ in $CD^t_{1,1}$, then the coordination to \textbf{stay} starts after $CD^t_{1,1}$.
\item If $i$ play $\langle x_i \rangle$ in $CD^t_{1,1}$, then the coordination to \textbf{revolt} will be initiate after $CD^t_{1,2}$ if he mimic the behavior of a pivotal player (i.e., by mimicking those players who played $\langle 1 \rangle$ in the equilibrium path).
\item If $i$ play $\langle x_i \rangle$ in $CD^t_{1,1}$, but he did not mimic the behavior of pivotal player, then such deviation will be detected.
\end{enumerate}

Thus, $i$'s expected static payoff after the coordination period in this $t$-block is at most 
\[
{\max\{\beta_{i}(E_2|h^{m}_{N_i})\times 1+\beta_{i}(E_1|h^{m}_{N_i})\times (-1), 0\}}
\]

However, if he stay in the equilibrium, there is a $t^s$ ($t^f$) such that Rebels play \textbf{revolt} (\textbf{stay}) contingent on $E_2$ ($E_1$), and thus after $t^*=\max\{t^s,t^f\}$ he get the expected payoff as
\[
{\max\{\beta_{i}(E_2|h^{m}_{N_i})\times 1, 0\}}
\]

After some calculation, after $t^*$, there is a loss of
\[\delta^{t^{*}}\frac{\min\{\beta_{i}(E_2|h^{m}_{G_i}),\beta_{i}(E_1|h^{m}_{G_i})\}}{1-\delta}\]
 



Note that $\beta_{i}(E_1|h^{m}_{N_i})>0$ and $\beta_{i}(E_2|h^{m}_{N_i})>0$, by $E_1$ and $E_2$ are not empty and by full support assumption.


\end{proof}







\begin{claim}
\label{claim_must_report_1}
Assume that player $i$ follows equilibrium path before $(RP)^t-1$ period. Then if $\beta_{i}(\#[Rebels](\theta)\geq k|h^{(RP)^t-1}_{G_i})>0$,  then if $i$ can report $\langle 1 \rangle$,  $i$ will not report $\langle \textbf{stay} \rangle$ when $\delta$ is high enough.
\end{claim}

\begin{proof}

There are two cases when $i$ can play $\langle 1 \rangle$.
\begin{itemize}

\item Case 1: If $\#I^{|RP^t|-1,t}_i\geq k$, let the event $E$ be
\[E=\{\theta: \#[Rebels](\theta)=\# I^{|RP^t|,t}_i\}\]

That is, the event that no more Rebels outside $i$'s information about Rebels. Contingent on $E$, there is no more Rebel can initiate the coordination. This is because for all $j\in O^{|RP^t|-1,t}_i$, $j$ is with $\# I^{t-1}_j< k-1$, and for all $j\in \bar{G}_i$ who have not yet reported, $j\not\in R^t$ since all the Rebels are in $I^{|RP^t|-1,t}_i$. Since only $i$ can initiate the coordination, if $i$ deviated, compared to equilibrium, there is a loss in expected continuation payoff as
\[\delta^q\frac{\beta_{i}(E|h^{(RP)^t-1}_{G_i})}{1-\delta}\], where $q$ is a period after $t$-block.

\item Case 2: If $\#I^{|RP^t|-1,t}_i= k-1$, since $\beta_{i}(\#[Rebels](\theta)\geq k|h^{|RP^t|}_{G_i})>0$, the following event $E_1$ must have positive probability; otherwise, since no neighbors can report after current period, and thus $\beta_{i}(\#[Rebels](\theta)\geq k|h^{|RP^t|}_{G_i})=0$.

Let
\[E_1=\{\theta: \exists j\in \bar{G}_i, j\notin O^{|RP^t|-1,t}_i [\#I^{|RP^t|-1,t}_j\geq k-1]\}\]


Let sub-events $E^{'}_1\subset E_1$ as

\[E^{'}_1=\{\theta: \text{ exist a unique} j\in \bar{G}_i, j\notin O^{|RP^t|-1,t}_i [\#I^{|RP^t|-1,t}_j\geq k-1]\}\] 

Note that this $E^{'}_1$ can be constructed since the network is tree. If there is $\theta$ admits 2 or more $j$s in the definition $E_1$, these $j$s are not each others' neighbor. Suppose there are two $j$s, says $j$, $j^{'}$, there must be at least one node in $I^{|RP^t|-1,t}_j$ but outside of $I^{|RP^t|-1,t}_{j^{'}}$. We then pick a $j$, and suppose those nodes outside $I^{|RP^t|-1,t}_j$ are all Inerts.

Now, dependent on such $j$, let
\[E=\{\theta:\#[Rebels](\theta)=\#I^{|RP^t|-1,t}_j\cup I^{|RP^t|-1,t}_i\}\]

If $i$ report $\langle \textbf{stay} \rangle$, there are following consequences.

\begin{itemize}
\item $j$ will believe that $i\notin R^t$, and thus $i$ can not initiate the coordination.
\item Such $j$ has $\#I^{|RP^t|,t}_j=\#I^t_j<k$. Since there is no more Rebel outside $I^{|RP^t|-1,t}_j\cup I^{|RP^t|-1,t}_i$ contingent on $E$, such $j$ will then play \text{stay} forever after $t$-block.
\item Without such extra Rebels in $I^{|RP^t|,t}_j$, only $\#I^{|RP^t|-1,t}_i= k-1$ Rebels may play \textbf{revolt}, and therefore there is no coordination to \textbf{revolt}
\end{itemize}

However, if $i$ play $\langle 1 \rangle$, coordination can be initiated by himself in the following coordination period. Thus, there is a loss in expected continuation payoff by
\[\delta^{q}\frac{\beta_{i}(E|h^{(RP)^t-1}_{G_i})}{1-\delta} \], where $q$ is a period after $t$-block.
\end{itemize}

\end{proof}




\begin{claim} 
\label{claim_report_with_no_message_coordination_period}
Assume that player $i$ follows equilibrium path before $(RP)^t$. Then, suppose there is no $j\in G_i$ has played $\langle 1 \rangle$ in $RP^t$, suppose $\# I^t_i<k$, and suppose $\# Ex_{I^{t}_i}\cup I^{t}_i \geq k$, then there is $\delta$ such that 
\begin{itemize}
\item if $i$ has not observed $\langle \textbf{stay} \rangle$ played by $j\in G_i$ in $CD^t_{1,2}$, or
\item if $i$ has not observed $\langle \mathbf{1}_j \rangle$ played by $j\in G_i$ in $CD^t_{q,2}$, $g\geq 2$
\end{itemize}
, then $i$ will not play
\begin{itemize}
\item $\langle \textbf{stay} \rangle$  in $CD^t_{1,2}$ and
\item $\langle \mathbf{1}_j \rangle$  in $CD^t_{q+1,2}$, $g\geq 2$
\end{itemize}
\end{claim}

\begin{proof}


If $i$ deviate, all $i$'s neighbor who did not detect the deviation will play $\textbf{revolt}$ after coordination period in this block; if $i$'s deviation is detected by some neighbors, we are in the case of Claim ~\ref{claim_detection_reporting_period} and so that $i$ will not deviate. We then check if $i$ deviate but no neighbor detect it.
Let 
\[E^{'}=\{\theta:\#I^{t}_i\leq k-1\}\]
and let 
\begin{eqnarray*}
E_1&=&\{\theta: \#[Reble](\theta)<k\}\cap E^{'}\\
E_2&=&\{\theta: \#[Reble](\theta)\geq k\}\cap E^{'}\\
\end{eqnarray*}

Since $\# I^t_i<k$ and $\# Ex_{I^{t}_i}\cup I^{t}_i \geq k$, due to the full support assumption and the equilibrium strategies played by $i$'s neighbors, we have 
\[0<\beta_{i}(\#[Rebels](\theta)\geq k|h^{m}_{G_i})<1\], and thus $E_1$ and $E_2$ have positive probability. Since after $i$'s deviation, all the Rebels will play \textbf{revolt} after this block, $i$'s expected static payoff after the coordination period in this $t$-block is at most 
\[
{\max\{\beta_{i}(E_2|h^{m}_{N_i})\times 1+\beta_{i}(E_1|h^{m}_{N_i})\times (-1), 0\}}
\]

However, if he stay in the equilibrium, there is a $t^s$ ($t^f$) such that Rebels play \textbf{revolt} (\textbf{stay}) contingent on $E_2$ ($E_1$), and thus after $t^*=\max\{t^s,t^f\}$ he get the expected payoff as
\[
{\max\{\beta_{i}(E_2|h^{m}_{N_i})\times 1, 0\}}
\]

After some calculation, after $t^*$, there is a loss of
\[\delta^{t^{*}}\frac{\min\{\beta_{i}(E_2|h^{m}_{G_i}),\beta_{i}(E_1|h^{m}_{G_i})\}}{1-\delta}\]

\end{proof}

After the above claims, we can take a sufficiently high $\delta$ to let all the above claims hold. Since a deviation is either detectable or non-detectable, and a deviation happens either in reporting period or coordination period, I conclude that this theorem holds by above claims. 




\end{document}
